{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/kownse/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "notebookstart= time.time()\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "#print(\"Data:\\n\",os.listdir(\"../input\"))\n",
    "\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# Viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import kaggle_util\n",
    "from profiler import profile\n",
    "from calcImgAtt import load\n",
    "import parse_att\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import string\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.cross_validation import KFold, StratifiedKFold\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "dict_att_path = '../input/dict_imgatt.pkl'\n",
    "NFOLDS = 5\n",
    "SEED = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = 1\n",
    "\n",
    "frm = 0\n",
    "to = 1503424\n",
    "if debug:    \n",
    "    frm = 0\n",
    "    to = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('../input/test.csv', skiprows=range(1,frm), nrows=to-frm, index_col = \"item_id\", parse_dates = [\"activation_date\"])\n",
    "train = pd.read_csv('../input/train.csv', skiprows=range(1,frm), nrows=to-frm, index_col = \"item_id\", parse_dates = [\"activation_date\"])\n",
    "df = pd.concat([train,test])\n",
    "testdex = df[pd.isnull(df['image_top_1'])].index\n",
    "traindex = df[pd.notnull(df['image_top_1'])].index\n",
    "\n",
    "train = df.loc[traindex]\n",
    "test = df.loc[testdex]\n",
    "\n",
    "len_train = len(train)\n",
    "df = pd.concat([train,test])\n",
    "\n",
    "y = train.image_top_1.copy().astype(np.uint16)\n",
    "df.drop(\"image_top_1\",axis=1, inplace=True)\n",
    "\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [\"user_id\",\"region\",\"city\",\"parent_category_name\",\n",
    "                   \"category_name\",\"user_type\",\n",
    "                   \"param_1\",\"param_2\",\"param_3\"]\n",
    "predictors = categorical.copy() + ['price']\n",
    "df = df[categorical + ['title', 'description', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/aggregated_features.csv')\n",
    "df = df.reset_index().merge(train_features, on = ['user_id'], how = 'left').set_index('item_id')\n",
    "df['avg_days_up_user'].fillna(0, inplace = True)\n",
    "df['avg_times_up_user'].fillna(0, inplace = True)\n",
    "df['n_user_items'].fillna(0, inplace = True)\n",
    "predictors += ['avg_days_up_user', 'avg_times_up_user', 'n_user_items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 59.64it/s]\n"
     ]
    }
   ],
   "source": [
    "lbl = preprocessing.LabelEncoder()\n",
    "for col in tqdm(categorical):\n",
    "    df[col].fillna('Unknown')\n",
    "    df[col] = lbl.fit_transform(df[col].astype(str))\n",
    "    if col == 'user_id':\n",
    "        df[col] = df[col].astype(np.uint32)\n",
    "    else:\n",
    "        df[col] = df[col].astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components = 20\n",
    "    \n",
    "lda_path = '../input/lda_{}_{}.npy'.format(frm, to)\n",
    "if os.path.exists(lda_path):\n",
    "    lda_categorical = np.load(lda_path)\n",
    "else:\n",
    "    lda = LDA(n_components=n_components, max_iter=5,\n",
    "              learning_method='online',\n",
    "              learning_offset=50.,\n",
    "              random_state=0)\n",
    "    lda_catergorical = [\"parent_category_name\",\n",
    "                   \"category_name\",\"user_type\",\"image_top_1\",\n",
    "                   \"param_1\",\"param_2\",\"param_3\"]\n",
    "    df_categorical = df[lda_catergorical]\n",
    "    lda_categorical = lda.fit_transform(df_categorical)\n",
    "    np.save(lda_path, lda_categorical)\n",
    "for i in range(n_components):\n",
    "    name = 'lda_cat_{}'.format(i)\n",
    "    df[name] = lda_categorical[:, i]\n",
    "    predictors.append(name)\n",
    "\n",
    "del lda_categorical\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "count = lambda l1, l2: sum([1 for x in l1 if x in l2])\n",
    "count_digit = lambda s : sum(c.isdigit() for c in s)\n",
    "count_num = lambda s : sum(c.isnumeric() for c in s.split())\n",
    "\n",
    "\n",
    "# Meta Text Features\n",
    "df['desc_punc'] = df['description'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "textfeats = [\"description\", \"title\"]\n",
    "for cols in tqdm(textfeats):\n",
    "    df[cols] = df[cols].astype(str).fillna('nicapotato') # FILL NA\n",
    "    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "    #df[cols] = df[cols].apply(lambda x: cleanName(x))\n",
    "\n",
    "    att_name = cols + '_num_chars'\n",
    "    predictors.append(att_name)\n",
    "    if att_name not in df.columns:\n",
    "        df[att_name] = df[cols].apply(len).astype(np.uint16) # Count number of Characters\n",
    "\n",
    "    att_name = cols + '_num_words'\n",
    "    predictors.append(att_name)\n",
    "    if att_name not in df.columns:\n",
    "        df[att_name] = df[cols].apply(lambda comment: len(comment.split())).astype(np.uint16) # Count number of Words\n",
    "\n",
    "    att_name = cols + '_num_unique_words'\n",
    "    predictors.append(att_name)\n",
    "    if att_name not in df.columns:\n",
    "        df[att_name] = df[cols].apply(lambda comment: len(set(w for w in comment.split()))).astype(np.uint16)\n",
    "\n",
    "    att_name = cols + '_words_vs_unique'\n",
    "    predictors.append(att_name)\n",
    "    if att_name not in df.columns:\n",
    "        df[att_name] = (df[cols+'_num_unique_words'] / df[cols+'_num_words'] * 100).astype(np.float32) # Count Unique Words\n",
    "\n",
    "    att_name = cols + '_punctuation'\n",
    "    predictors.append(att_name)\n",
    "    if att_name not in df.columns:\n",
    "        df[att_name] = df[cols].apply(count, args=(string.punctuation,)).astype(np.uint16)\n",
    "\n",
    "    att_name = cols + '_digit'\n",
    "    predictors.append(att_name)\n",
    "    if att_name not in df.columns:\n",
    "        df[att_name] = df[cols].apply(count_digit).astype(np.uint16)\n",
    "\n",
    "    att_name = cols + '_num'\n",
    "    predictors.append(att_name)\n",
    "    if att_name not in df.columns:\n",
    "        df[att_name] = df[cols].apply(count_num).astype(np.uint16)\n",
    "\n",
    "    att_name = cols + '_num_letters'\n",
    "    predictors.append(att_name)\n",
    "    if att_name not in df.columns:\n",
    "        df[att_name] = df[cols].apply(lambda comment: len(comment)).astype(np.uint16)\n",
    "\n",
    "#df['description_num_letters'] = df['description_num_letters'] + 1\n",
    "#df['description_num_words'] = df['description_num_words'] + 1\n",
    "df['title_desc_len_ratio'] = df['title_num_letters']/df['description_num_letters']\n",
    "df['desc_num_ratio'] = df['description_num']/df['description_num_words']\n",
    "predictors += ['title_desc_len_ratio', 'desc_num_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['region', 'parent_category_name', 'category_name'] ['count', 'cumcount', 'nunique']\n",
      "group feature: region_parent_category_name_category_name_count\n",
      "calculate from scratch: region_parent_category_name_category_name_count\n",
      "group feature: region_parent_category_name_category_name_cumcount\n",
      "load from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 1/21 [00:00<00:05,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group feature: region_parent_category_name_category_name_nunique\n",
      "load from file\n",
      "['parent_category_name', 'category_name', 'price'] ['count', 'zscore']\n",
      "group feature: parent_category_name_category_name_price_count\n",
      "calculate from scratch: parent_category_name_category_name_price_count\n",
      "group feature: parent_category_name_category_name_price_zscore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 2/21 [00:00<00:04,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from file\n",
      "['user_id', 'price'] ['count', 'cumcount']\n",
      "group feature: user_id_price_count\n",
      "calculate from scratch: user_id_price_count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 3/21 [00:00<00:04,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group feature: user_id_price_cumcount\n",
      "load from file\n",
      "['user_id', 'parent_category_name', 'category_name', 'price'] ['count', 'cumcount']\n",
      "group feature: user_id_parent_category_name_category_name_price_count\n",
      "calculate from scratch: user_id_parent_category_name_category_name_price_count\n",
      "group feature: user_id_parent_category_name_category_name_price_cumcount\n",
      "load from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 4/21 [00:00<00:03,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['region', 'city', 'parent_category_name', 'category_name', 'price'] ['count', 'zscore']\n",
      "group feature: region_city_parent_category_name_category_name_price_count\n",
      "calculate from scratch: region_city_parent_category_name_category_name_price_count\n",
      "group feature: region_city_parent_category_name_category_name_price_zscore\n",
      "load from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 6/21 [00:01<00:02,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parent_category_name', 'category_name', 'description_num_chars'] ['zscore']\n",
      "group feature: parent_category_name_category_name_description_num_chars_zscore\n",
      "load from file\n",
      "['parent_category_name', 'category_name', 'description_num_words'] ['zscore']\n",
      "group feature: parent_category_name_category_name_description_num_words_zscore\n",
      "load from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 8/21 [00:01<00:02,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parent_category_name', 'category_name', 'description_num_unique_words'] ['zscore']\n",
      "group feature: parent_category_name_category_name_description_num_unique_words_zscore\n",
      "load from file\n",
      "['parent_category_name', 'category_name', 'description_words_vs_unique'] ['zscore']\n",
      "group feature: parent_category_name_category_name_description_words_vs_unique_zscore\n",
      "load from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 10/21 [00:01<00:01,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parent_category_name', 'category_name', 'description_punctuation'] ['zscore']\n",
      "group feature: parent_category_name_category_name_description_punctuation_zscore\n",
      "load from file\n",
      "['parent_category_name', 'category_name', 'description_digit'] ['zscore']\n",
      "group feature: parent_category_name_category_name_description_digit_zscore\n",
      "load from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 12/21 [00:01<00:01,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parent_category_name', 'category_name', 'description_num'] ['zscore']\n",
      "group feature: parent_category_name_category_name_description_num_zscore\n",
      "load from file\n",
      "['parent_category_name', 'category_name', 'title_num_chars'] ['zscore']\n",
      "group feature: parent_category_name_category_name_title_num_chars_zscore\n",
      "load from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 14/21 [00:02<00:01,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parent_category_name', 'category_name', 'title_num_words'] ['zscore']\n",
      "group feature: parent_category_name_category_name_title_num_words_zscore\n",
      "load from file\n",
      "['parent_category_name', 'category_name', 'title_num_unique_words'] ['zscore']\n",
      "group feature: parent_category_name_category_name_title_num_unique_words_zscore\n",
      "load from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 16/21 [00:02<00:00,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parent_category_name', 'category_name', 'title_words_vs_unique'] ['zscore']\n",
      "group feature: parent_category_name_category_name_title_words_vs_unique_zscore\n",
      "load from file\n",
      "['parent_category_name', 'category_name', 'title_punctuation'] ['zscore']\n",
      "group feature: parent_category_name_category_name_title_punctuation_zscore\n",
      "load from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 18/21 [00:02<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parent_category_name', 'category_name', 'title_digit'] ['zscore']\n",
      "group feature: parent_category_name_category_name_title_digit_zscore\n",
      "load from file\n",
      "['parent_category_name', 'category_name', 'title_num'] ['zscore']\n",
      "group feature: parent_category_name_category_name_title_num_zscore\n",
      "load from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 20/21 [00:02<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parent_category_name', 'category_name', 'title_desc_len_ratio'] ['zscore']\n",
      "group feature: parent_category_name_category_name_title_desc_len_ratio_zscore\n",
      "load from file\n",
      "['parent_category_name', 'category_name', 'desc_num_ratio'] ['zscore']\n",
      "group feature: parent_category_name_category_name_desc_num_ratio_zscore\n",
      "load from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:02<00:00,  7.33it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_list = [\n",
    "        (['region', 'parent_category_name', 'category_name'], ['count', 'cumcount', 'nunique']),\n",
    "\n",
    "        (['parent_category_name', 'category_name', 'price'], ['count', 'zscore']),\n",
    "\n",
    "        (['user_id', 'price'], ['count', 'cumcount']),\n",
    "        (['user_id', 'parent_category_name', 'category_name', 'price'], ['count', 'cumcount']),\n",
    "        (['region', 'city', 'parent_category_name', 'category_name', 'price'], ['count', 'zscore']),\n",
    "\n",
    "        (['parent_category_name', 'category_name', 'description_num_chars'], ['zscore']),\n",
    "        (['parent_category_name', 'category_name', 'description_num_words'], ['zscore']),\n",
    "        (['parent_category_name', 'category_name', 'description_num_unique_words'], ['zscore']),\n",
    "        (['parent_category_name', 'category_name', 'description_words_vs_unique'], ['zscore']),\n",
    "        (['parent_category_name', 'category_name', 'description_punctuation'], ['zscore']),\n",
    "        (['parent_category_name', 'category_name', 'description_digit'], ['zscore']),\n",
    "        (['parent_category_name', 'category_name', 'description_num'], ['zscore']),\n",
    "\n",
    "\n",
    "        (['parent_category_name', 'category_name', 'title_num_chars'], ['zscore']),\n",
    "        (['parent_category_name', 'category_name', 'title_num_words'], ['zscore']),\n",
    "        (['parent_category_name', 'category_name', 'title_num_unique_words'], ['zscore']),\n",
    "        (['parent_category_name', 'category_name', 'title_words_vs_unique'], ['zscore']),\n",
    "        (['parent_category_name', 'category_name', 'title_punctuation'], ['zscore']),\n",
    "        (['parent_category_name', 'category_name', 'title_digit'], ['zscore']),\n",
    "        (['parent_category_name', 'category_name', 'title_num'], ['zscore']),\n",
    "\n",
    "        (['parent_category_name', 'category_name', 'title_desc_len_ratio'], ['zscore']),\n",
    "        (['parent_category_name', 'category_name', 'desc_num_ratio'], ['zscore']),\n",
    "        ]\n",
    "\n",
    "\n",
    "for (selcol, how) in tqdm(feature_list):\n",
    "    print('{} {}'.format(selcol, how))\n",
    "    df, sub_changed = parse_att.calcGroupFeatureBulk(df, selcol, how, frm, to, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:00<00:00, 957.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 9.16 MB\n",
      "Memory usage after optimization is: 3.34 MB\n",
      "Decreased by 63.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = kaggle_util.reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TF-IDF] Term Frequency Inverse Document Frequency Stage\n",
      "Vectorization Runtime: 0.10 Minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[TF-IDF] Term Frequency Inverse Document Frequency Stage\")\n",
    "russian_stop = set(stopwords.words('russian'))\n",
    "\n",
    "tfidf_para = {\n",
    "    \"stop_words\": russian_stop,\n",
    "    \"analyzer\": 'word',\n",
    "    \"token_pattern\": r'\\w{1,}',\n",
    "    \"sublinear_tf\": True,\n",
    "    \"dtype\": np.float32,\n",
    "    \"norm\": 'l2',\n",
    "    #\"min_df\":5,\n",
    "    #\"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "}\n",
    "def get_col(col_name): return lambda x: x[col_name]\n",
    "vectorizer = FeatureUnion([\n",
    "        ('description',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=17000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('description'))),\n",
    "\n",
    "        ('title',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            **tfidf_para,\n",
    "            #max_features=7000,\n",
    "            preprocessor=get_col('title')))\n",
    "    ])   \n",
    "\n",
    "start_vect=time.time()\n",
    "vectorizer.fit(df.loc[traindex].to_dict('records'))\n",
    "ready_df = vectorizer.transform(df.to_dict('records'))\n",
    "tfvocab = vectorizer.get_feature_names()\n",
    "print(\"Vectorization Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))\n",
    "\n",
    "# Drop Text Cols\n",
    "df.drop(textfeats, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[predictors]\n",
    "tfvocab = df.columns.tolist() + tfvocab\n",
    "testing = hstack([csr_matrix(df[len_train:].values),ready_df[len_train:]])\n",
    "df = df.loc[traindex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params =  {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'metric' : 'multi_logloss',\n",
    "        'num_class' : 3067,\n",
    "        'num_leaves': 270,# 37,\n",
    "        'feature_fraction': 0.5,\n",
    "        'bagging_fraction': 0.75,\n",
    "        'learning_rate': 0.016,\n",
    "        'nthread': 6,\n",
    "        'verbose': 0,\n",
    "        'drop_rate': 0.02\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:553: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=2.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8551 9924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/kownse/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-fb836d94e7ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mvalid_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1522\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1523\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1525\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nfold = 2 if debug else 5\n",
    "skf = StratifiedKFold(y, n_folds=nfold)\n",
    "for i, (train_split, val_split) in enumerate(skf):\n",
    "\n",
    "    print(len(train_split),len(val_split))\n",
    "    X_train = hstack([csr_matrix(df.iloc[train_split].values),ready_df[train_split]])\n",
    "    X_valid = hstack([csr_matrix(df.iloc[val_split].values),ready_df[val_split]]) # Sparse Matrix \n",
    "    y_train = y[train_split]\n",
    "    y_valid = y[val_split]\n",
    "\n",
    "    lgtrain = lgb.Dataset(X_train, y_train,\n",
    "                    feature_name=tfvocab,\n",
    "                    categorical_feature = categorical)\n",
    "    lgvalid = lgb.Dataset(X_valid, y_valid,\n",
    "                    feature_name=tfvocab,\n",
    "                    categorical_feature = categorical)\n",
    "\n",
    "    modelstart = time.time()\n",
    "    lgb_clf = lgb.train(\n",
    "        lgbm_params,\n",
    "        lgtrain,\n",
    "        num_boost_round=26000,\n",
    "        valid_sets=[lgtrain, lgvalid],\n",
    "        valid_names=['train','valid'],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
