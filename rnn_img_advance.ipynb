{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import time \n",
    "import gc \n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dropout, Concatenate, Dense, Embedding, SpatialDropout1D, concatenate\n",
    "from keras.layers import CuDNNGRU, PReLU, GRU, LSTM, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, BatchNormalization, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from attention_with_context import AttentionWithContext\n",
    "from keras.losses import categorical_crossentropy, sparse_categorical_crossentropy\n",
    "from Attention import Attention\n",
    "from capsule import Capsule\n",
    "import kaggle_util\n",
    "import string\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "import threading\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from contextlib import closing\n",
    "cores = 4\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightgbm_avito import calcImgAtt\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "max_seq_title_description_length = 300\n",
    "max_seq_title_length = 30\n",
    "max_words_title_description = 200000\n",
    "EMBEDDING_DIM1 = 300\n",
    "emb_size = 10\n",
    "gru_size = 50\n",
    "\n",
    "debug = 1\n",
    "nfold = 10\n",
    "\n",
    "frm = 0\n",
    "to = 1503424\n",
    "if debug:    \n",
    "    frm = 0\n",
    "    to = 1000\n",
    "    \n",
    "region_map = {\"Свердловская область\" : \"Sverdlovsk oblast\",\n",
    "            \"Самарская область\" : \"Samara oblast\",\n",
    "            \"Ростовская область\" : \"Rostov oblast\",\n",
    "            \"Татарстан\" : \"Tatarstan\",\n",
    "            \"Волгоградская область\" : \"Volgograd oblast\",\n",
    "            \"Нижегородская область\" : \"Nizhny Novgorod oblast\",\n",
    "            \"Пермский край\" : \"Perm Krai\",\n",
    "            \"Оренбургская область\" : \"Orenburg oblast\",\n",
    "            \"Ханты-Мансийский АО\" : \"Khanty-Mansi Autonomous Okrug\",\n",
    "            \"Тюменская область\" : \"Tyumen oblast\",\n",
    "            \"Башкортостан\" : \"Bashkortostan\",\n",
    "            \"Краснодарский край\" : \"Krasnodar Krai\",\n",
    "            \"Новосибирская область\" : \"Novosibirsk oblast\",\n",
    "            \"Омская область\" : \"Omsk oblast\",\n",
    "            \"Белгородская область\" : \"Belgorod oblast\",\n",
    "            \"Челябинская область\" : \"Chelyabinsk oblast\",\n",
    "            \"Воронежская область\" : \"Voronezh oblast\",\n",
    "            \"Кемеровская область\" : \"Kemerovo oblast\",\n",
    "            \"Саратовская область\" : \"Saratov oblast\",\n",
    "            \"Владимирская область\" : \"Vladimir oblast\",\n",
    "            \"Калининградская область\" : \"Kaliningrad oblast\",\n",
    "            \"Красноярский край\" : \"Krasnoyarsk Krai\",\n",
    "            \"Ярославская область\" : \"Yaroslavl oblast\",\n",
    "            \"Удмуртия\" : \"Udmurtia\",\n",
    "            \"Алтайский край\" : \"Altai Krai\",\n",
    "            \"Иркутская область\" : \"Irkutsk oblast\",\n",
    "            \"Ставропольский край\" : \"Stavropol Krai\",\n",
    "            \"Тульская область\" : \"Tula oblast\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### rmse loss for keras\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred))) \n",
    "\n",
    "def clean_data(dataset):\n",
    "    dataset['param_1'].fillna(value='missing', inplace=True)\n",
    "    dataset['param_2'].fillna(value='missing', inplace=True)\n",
    "    dataset['param_3'].fillna(value='missing', inplace=True)\n",
    "    \n",
    "    dataset['param_1'] = dataset['param_1'].astype(str)\n",
    "    dataset['param_2'] = dataset['param_2'].astype(str)\n",
    "    dataset['param_3'] = dataset['param_3'].astype(str)\n",
    "    \n",
    "    dataset['param123'] = (dataset['param_1']+'_'+dataset['param_2']+'_'+dataset['param_3']).astype(str)\n",
    "    del dataset['param_2'], dataset['param_3']\n",
    "    gc.collect()\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(\"Filling Missing Values.....\")\n",
    "    \n",
    "    dataset['price'] = dataset['price'].fillna(0).astype('float32')\n",
    "    \n",
    "    print(\"Casting data types to type Category.......\")\n",
    "    dataset['category_name'] = dataset['category_name'].astype('category')\n",
    "    dataset['parent_category_name'] = dataset['parent_category_name'].astype('category')\n",
    "    dataset['region'] = dataset['region'].astype('category')\n",
    "    dataset['city'] = dataset['city'].astype('category')\n",
    "    \n",
    "    dataset = clean_data(dataset)\n",
    "        \n",
    "    print(\"PreProcessing Function completed.\")\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def get_numcols(dataset):\n",
    "    non_num_cols = ['seq_description', 'seq_title', 'user_id'] + emb_cols\n",
    "    num_cols = []\n",
    "    \n",
    "    X = {}\n",
    "    for c in dataset.columns:         \n",
    "        if c not in non_num_cols:\n",
    "            num_cols.append(c)\n",
    "            \n",
    "    return num_cols\n",
    "\n",
    "\n",
    "def num_log(df):\n",
    "    df['price'] = np.log1p(df['price'])\n",
    "    df['avg_days_up_user'] = np.log1p(df['avg_days_up_user'])\n",
    "    df['avg_times_up_user'] = np.log1p(df['avg_times_up_user'])\n",
    "    df['n_user_items'] = np.log1p(df['n_user_items'])\n",
    "    df['item_seq_number'] = np.log(df['item_seq_number'])\n",
    "\n",
    "    num_cols = get_numcols(df)\n",
    "    #print(num_cols)\n",
    "    #print(df[num_cols].head())\n",
    "    #print(df[num_cols].isnull().sum())\n",
    "    scaler = MinMaxScaler()\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def keras_fit(train):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    train['title_description']= (train['title']+\" \"+train['description']).astype(str)\n",
    "    \n",
    "    print(\"Start Tokenization.....\")\n",
    "    tokenizer = kaggle_util.get_text_tokenizer(train, 'title_description', max_words_title_description)\n",
    "    \n",
    "    regional = pd.read_csv('../input/regional.csv', index_col=0)\n",
    "    regional.index = regional.index.str.lower()\n",
    "\n",
    "    train['region'] = train['region'].apply(lambda x : region_map[x])\n",
    "    train['region'] = train['region'].str.lower()\n",
    "    train[\"reg_dense\"] = train['region'].apply(lambda x: regional.loc[x,\"Density_of_region(km2)\"])\n",
    "    train[\"rural\"] = train['region'].apply(lambda x: regional.loc[x,\"Rural_%\"])\n",
    "    train[\"reg_Time_zone\"] = train['region'].apply(lambda x: regional.loc[x,\"Time_zone\"])\n",
    "    train[\"reg_Population\"] = train['region'].apply(lambda x: regional.loc[x,\"Total_population\"])\n",
    "    train[\"reg_Urban\"] = train['region'].apply(lambda x: regional.loc[x,\"Urban%\"])\n",
    "\n",
    "    dict_encoder = {}\n",
    "    for col in emb_cols:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(train[col])\n",
    "        dict_encoder[col] = encoder\n",
    "    \n",
    "    print(\"Fit on Train Function completed.\")\n",
    "    \n",
    "    return train, tokenizer, dict_encoder\n",
    "\n",
    "def deal_text_feature(dataset):\n",
    "    t1 = time.time()\n",
    "    \n",
    "    #dataset['title_description'].fillna('', inplace=True)\n",
    "    #dataset['seq_title_description']= tokenizer.texts_to_sequences(dataset.title_description.str.lower())\n",
    "    \n",
    "    count = lambda l1, l2: sum([1 for x in l1 if x in l2])\n",
    "    count_digit = lambda s : sum(c.isdigit() for c in s)\n",
    "    count_num = lambda s : sum(c.isnumeric() for c in s.split())\n",
    "    \n",
    "    dataset['description'].fillna('unknown', inplace=True)\n",
    "    dataset['title'].fillna('unknown', inplace=True)\n",
    "    \n",
    "    predictors = []\n",
    "    textfeats = [\"description\", \"title\"]\n",
    "    for cols in tqdm(textfeats):\n",
    "        dataset[cols] = dataset[cols].str.lower()\n",
    "           \n",
    "        att_name = cols + '_num_words'\n",
    "        predictors.append(att_name)\n",
    "        dataset[att_name] = dataset[cols].apply(lambda comment: len(comment.split())).astype(np.uint16) # Count number of Words\n",
    "            \n",
    "        att_name = cols + '_num_unique_words'\n",
    "        predictors.append(att_name)\n",
    "        dataset[att_name] = dataset[cols].apply(lambda comment: len(set(w for w in comment.split()))).astype(np.uint16)\n",
    "            \n",
    "        att_name = cols + '_words_vs_unique'\n",
    "        predictors.append(att_name)\n",
    "        dataset[att_name] = (dataset[cols+'_num_unique_words'] / dataset[cols+'_num_words']).astype(np.float32) # Count Unique Words\n",
    "            \n",
    "        att_name = cols + '_punctuation'\n",
    "        predictors.append(att_name)\n",
    "        dataset[att_name] = dataset[cols].apply(count, args=(string.punctuation,)).astype(np.uint16)\n",
    "           \n",
    "        att_name = cols + '_num'\n",
    "        predictors.append(att_name)\n",
    "        dataset[att_name] = dataset[cols].apply(count_num).astype(np.uint16)\n",
    "            \n",
    "    dataset['title_desc_len_ratio'] = dataset['title_num_words']/dataset['description_num_words']\n",
    "    #dataset['desc_num_ratio'] = dataset['description_num']/dataset['description_num_words']\n",
    "    predictors += ['title_desc_len_ratio']#, 'desc_num_ratio']\n",
    "    \n",
    "    dataset['seq_description']= tokenizer.texts_to_sequences(dataset.description.str.lower())\n",
    "    dataset['seq_title']= tokenizer.texts_to_sequences(dataset.title.str.lower())\n",
    "    \n",
    "    print(\"Transform done for test\")\n",
    "    print(\"Time taken for Sequence Tokens is\"+str(time.time()-t1))\n",
    "    \n",
    "    del dataset['title_description']\n",
    "    del dataset['description'], dataset['title']\n",
    "    gc.collect()\n",
    "    \n",
    "    return dataset, predictors\n",
    "\n",
    "def keras_train_transform(dataset):\n",
    "    print('transform...')\n",
    "    dataset, txt_stats = deal_text_feature(dataset)\n",
    "    \n",
    "    for key in dict_encoder.keys():\n",
    "        #print(key)\n",
    "        dataset[key] = dict_encoder[key].transform(dataset[key])\n",
    "    \n",
    "    dataset = kaggle_util.reduce_mem_usage(dataset)\n",
    "    print(\"Transform on test function completed.\")\n",
    "    \n",
    "    dataset = num_log(dataset)\n",
    "    \n",
    "    return dataset, txt_stats\n",
    "    \n",
    "def get_keras_data(dataset):\n",
    "    X = {}\n",
    "    for c in dataset.columns:\n",
    "        if c in ['item_id', 'user_id']:\n",
    "            continue   \n",
    "        elif c == 'seq_description':\n",
    "            X[c] = pad_sequences(dataset[c], maxlen=max_seq_title_description_length)\n",
    "        elif c == 'seq_title':\n",
    "            X[c] = pad_sequences(dataset[c], maxlen=max_seq_title_length)\n",
    "        \n",
    "        #if c == 'seq_title_description':\n",
    "        #    X[c] = pad_sequences(dataset[c], maxlen=max_seq_title_description_length)\n",
    "        else:\n",
    "            X[c] = dataset[c].values\n",
    "            \n",
    "\n",
    "    print(\"Data ready for Vectorization\")\n",
    "    \n",
    "    return X\n",
    "\n",
    "def RNN_model(emb_cols, num_cols):\n",
    "#def RNN_model():\n",
    "\n",
    "    #Inputs\n",
    "    #seq_title_description = Input(shape=[max_seq_title_description_length], name=\"seq_title_description\")\n",
    "    seq_description = Input(shape=[max_seq_title_description_length], name=\"seq_description\")\n",
    "    seq_title = Input(shape=[max_seq_title_length], name=\"seq_title\")\n",
    "    \n",
    "    emb_inputs = []\n",
    "    emb_layers = []\n",
    "    for col in emb_cols:\n",
    "        emb_input = Input(shape=[1], name=col)\n",
    "        emb_inputs.append(emb_input)\n",
    "        \n",
    "        emb_layer = Embedding(dict_emb_max[col], emb_size)(emb_input)\n",
    "        emb_layers.append(Flatten()(emb_layer))\n",
    "        \n",
    "    num_inputs = []\n",
    "    for col in num_cols:\n",
    "        num_inputs.append(Input(shape=[1], name=col))\n",
    "    \n",
    "    #Embeddings layers\n",
    "    \n",
    "    \n",
    "    #emb_seq_title_description = Embedding(vocab_size, EMBEDDING_DIM1, weights = [embedding_matrix1], trainable = False)(seq_title_description)\n",
    "    emb_seq_description = Embedding(vocab_size, EMBEDDING_DIM1, weights = [embedding_matrix1], trainable = False)(seq_description)\n",
    "    emb_seq_title = Embedding(vocab_size, EMBEDDING_DIM1, weights = [embedding_matrix1], trainable = False)(seq_title)\n",
    "    \n",
    "    \"\"\"\n",
    "    rnn_layer1 = Bidirectional(CuDNNGRU(gru_size, return_sequences=True))(emb_seq_title_description)\n",
    "    rnn_layer1 = AttentionWithContext()(rnn_layer1)\n",
    "    \n",
    "    Routings = 6\n",
    "    Num_capsule = 10\n",
    "    Dim_capsule = 16\n",
    "    capsule = Capsule(num_capsule=Num_capsule, dim_capsule=Dim_capsule, routings=Routings,\n",
    "                          share_weights=True)(rnn_layer1)\n",
    "    rnn_layer1 = Flatten()(capsule)\n",
    "    \"\"\"\n",
    "    \n",
    "    #rnn_layer1 = CuDNNGRU(gru_size)(emb_seq_title_description)\n",
    "    rnn_layer1 = CuDNNGRU(gru_size)(emb_seq_description)\n",
    "    rnn_layer2 = CuDNNGRU(gru_size)(emb_seq_title)\n",
    "    #rnn_layer1 = CuDNNGRU(gru_size, return_sequences=True)(emb_seq_description)\n",
    "    #rnn_layer2 = CuDNNGRU(gru_size, return_sequences=True)(emb_seq_title)\n",
    "    #rnn_layer1 = Attention()(rnn_layer1)\n",
    "    #rnn_layer2 = Attention()(rnn_layer2)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    rnn_layer1 = Bidirectional(CuDNNGRU(gru_size, return_sequences=True))(emb_seq_title_description)\n",
    "    avg_tensor = GlobalAveragePooling1D()(rnn_layer1)\n",
    "    max_tensor = GlobalMaxPooling1D()(rnn_layer1)\n",
    "    rnn_layer1 = Concatenate()([avg_tensor, max_tensor])\n",
    "    \"\"\"\n",
    "    #main layer\n",
    "    main_l = concatenate([rnn_layer1, rnn_layer2] + emb_layers + num_inputs)\n",
    "        \n",
    "    #main_l = Dropout(0.1)(Dense(512,activation='relu') (main_l))\n",
    "    #main_l = Dropout(0.1)(Dense(64,activation='relu') (main_l))\n",
    "    \n",
    "    \n",
    "    main_l = BatchNormalization()(main_l)\n",
    "    #main_l = Dropout(0.1)(main_l) # maybe bad \n",
    "    main_l = Dense(512)(main_l)\n",
    "    main_l = PReLU()(main_l)\n",
    "    main_l = BatchNormalization()(main_l)\n",
    "    main_l = Dropout(0.1)(main_l)\n",
    "    main_l = Dense(256)(main_l)\n",
    "    main_l = PReLU()(main_l)\n",
    "    main_l = BatchNormalization()(main_l)\n",
    "    main_l = Dropout(0.1)(main_l)\n",
    "    \n",
    "    \n",
    "    #output\n",
    "    output = Dense(3067,activation=\"softmax\") (main_l)\n",
    "    \n",
    "    #model\n",
    "    inputs = [seq_description, seq_title] + emb_inputs + num_inputs\n",
    "    model = Model(inputs, output)\n",
    "                  \n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss= sparse_categorical_crossentropy,\n",
    "                  metrics = [sparse_categorical_crossentropy])\n",
    "    return model\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "\n",
    "    Rsum = np.sum((y - y_pred)**2)\n",
    "    n = y.shape[0]\n",
    "    RMSE = np.sqrt(Rsum/n)\n",
    "    return RMSE \n",
    "\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Train data - No Params, No Image data \n",
    "dtypes_train = {\n",
    "                'price': 'float32',\n",
    "                'item_seq_number': 'uint32'\n",
    "}\n",
    "\n",
    "# No user_id\n",
    "train_cols = ['item_id', 'user_id', 'region', 'city', 'parent_category_name', 'category_name',\n",
    "   'param_1', 'param_2', 'param_3', 'title', 'description', 'price',\n",
    "   'item_seq_number', 'user_type', 'image_top_1']\n",
    "train = pd.read_csv(\"../input/train.csv\", skiprows=range(1,frm), nrows=to-frm, \n",
    "                    dtype = dtypes_train, \n",
    "                    index_col = \"item_id\",\n",
    "                   usecols = train_cols)\n",
    "\n",
    "test = pd.read_csv(\"../input/test.csv\", skiprows=range(1,frm), nrows=to-frm, dtype = dtypes_train, index_col = \"item_id\", usecols = train_cols)\n",
    "testdex = test.index\n",
    "\n",
    "df = pd.concat([train, test], axis = 0)\n",
    "testdex = df[pd.isnull(df['image_top_1'])].index\n",
    "traindex = df[pd.notnull(df['image_top_1'])].index\n",
    "\n",
    "train = df.loc[traindex]\n",
    "test = df.loc[testdex]\n",
    "\n",
    "y_train = np.array(train['image_top_1'])\n",
    "\n",
    "len_train = len(train)\n",
    "train = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "PreProcessing Function completed.\n",
      "Start Tokenization.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 30.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit on Train Function completed.\n",
      "transform...\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is0.1725459098815918\n",
      "Memory usage of dataframe is 0.34 MB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 31/31 [00:00<00:00, 1400.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage after optimization is: 0.16 MB\n",
      "Decreased by 54.4%\n",
      "Transform on test function completed.\n",
      "Tokenization done and TRAIN READY FOR Validation splitting\n",
      "(16319, 300)\n",
      "13617 2700 2700 13617\n",
      "(16319, 300)\n",
      "Data ready for Vectorization\n",
      "test shape: (158, 30)\n",
      "num_cols:\n",
      "['price', 'item_seq_number', 'avg_days_up_user', 'avg_times_up_user', 'n_user_items', 'reg_dense', 'rural', 'reg_Population', 'reg_Urban', 'description_num_words', 'description_num_unique_words', 'description_words_vs_unique', 'description_punctuation', 'description_num', 'title_num_words', 'title_num_unique_words', 'title_words_vs_unique', 'title_punctuation', 'title_num', 'title_desc_len_ratio']\n"
     ]
    }
   ],
   "source": [
    "del train['image_top_1']\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "train_features = pd.read_csv('../input/aggregated_features.csv')\n",
    "train = train.merge(train_features, on = ['user_id'], how = 'left')\n",
    "del train_features\n",
    "gc.collect()\n",
    "\n",
    "train['avg_days_up_user'] = train['avg_days_up_user'].fillna(0).astype('uint32')\n",
    "train['avg_times_up_user'] = train['avg_times_up_user'].fillna(0).astype('uint32')\n",
    "train['n_user_items'] = train['n_user_items'].fillna(0).astype('uint32')\n",
    "\n",
    "emb_cols = ['region', 'city', 'category_name', 'parent_category_name', 'user_type',\n",
    "            'param_1', 'param123', 'reg_Time_zone']\n",
    "\n",
    "train = preprocess_dataset(train)\n",
    "train, tokenizer, dict_encoder = keras_fit(train)\n",
    "train, txt_stats = keras_train_transform(train)\n",
    "print(\"Tokenization done and TRAIN READY FOR Validation splitting\")\n",
    "\n",
    "# Calculation of max values for Categorical fields \n",
    "\n",
    "dict_emb_max = {}\n",
    "for col in emb_cols:\n",
    "    dict_emb_max[col] = train[col].max() + 2\n",
    "\n",
    "#del train['item_id'], \n",
    "del train['user_id']\n",
    "gc.collect()\n",
    "\n",
    "EMBEDDING_FILE1 = '../input/wiki.ru.vec'\n",
    "embedding_matrix1, vocab_size = kaggle_util.build_emb_matrix_from_tokenizer(tokenizer, EMBEDDING_FILE1, EMBEDDING_DIM1)\n",
    "\n",
    "test = train[len_train:]\n",
    "train = train[:len_train]\n",
    "X_test = get_keras_data(test)\n",
    "num_cols = get_numcols(test)\n",
    "print('test shape: {}'.format(test.shape))\n",
    "print('num_cols:')\n",
    "print(num_cols)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import time \n",
    "\n",
    "skf = KFold(n_splits = nfold)\n",
    "Kfold_preds_final = []\n",
    "k = 0\n",
    "RMSE = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (1657, 30) (185, 30)\n",
      "(1657,) (185,)\n",
      "Data ready for Vectorization\n",
      "Data ready for Vectorization\n"
     ]
    }
   ],
   "source": [
    "train_idx, test_idx = next(skf.split(train.values, y_train))\n",
    "X_train1, X_test1 = train.iloc[train_idx], train.iloc[test_idx]\n",
    "print('input shape: ', X_train1.shape, X_test1.shape)\n",
    "y_train1, y_test1 = y_train[train_idx], y_train[test_idx]\n",
    "print(y_train1.shape, y_test1.shape)\n",
    "gc.collect()\n",
    "\n",
    "X_train_final = get_keras_data(X_train1)\n",
    "X_test_final = get_keras_data(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1657 samples, validate on 185 samples\n",
      "Epoch 1/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 8.0725 - sparse_categorical_crossentropy: 8.0725 - val_loss: 7.5549 - val_sparse_categorical_crossentropy: 7.5549\n",
      "\n",
      "Epoch 00001: val_sparse_categorical_crossentropy improved from inf to 7.55486, saving model to ../model/bestrnnimg_0.hdf5\n",
      "Epoch 2/100\n",
      "1657/1657 [==============================] - 0s 99us/step - loss: 6.1938 - sparse_categorical_crossentropy: 6.1938 - val_loss: 7.1055 - val_sparse_categorical_crossentropy: 7.1055\n",
      "\n",
      "Epoch 00002: val_sparse_categorical_crossentropy improved from 7.55486 to 7.10553, saving model to ../model/bestrnnimg_0.hdf5\n",
      "Epoch 3/100\n",
      "1657/1657 [==============================] - 0s 101us/step - loss: 4.7235 - sparse_categorical_crossentropy: 4.7235 - val_loss: 6.7541 - val_sparse_categorical_crossentropy: 6.7541\n",
      "\n",
      "Epoch 00003: val_sparse_categorical_crossentropy improved from 7.10553 to 6.75412, saving model to ../model/bestrnnimg_0.hdf5\n",
      "Epoch 4/100\n",
      "1657/1657 [==============================] - 0s 101us/step - loss: 3.3329 - sparse_categorical_crossentropy: 3.3329 - val_loss: 6.5321 - val_sparse_categorical_crossentropy: 6.5321\n",
      "\n",
      "Epoch 00004: val_sparse_categorical_crossentropy improved from 6.75412 to 6.53212, saving model to ../model/bestrnnimg_0.hdf5\n",
      "Epoch 5/100\n",
      "1657/1657 [==============================] - 0s 98us/step - loss: 2.1066 - sparse_categorical_crossentropy: 2.1066 - val_loss: 6.4437 - val_sparse_categorical_crossentropy: 6.4437\n",
      "\n",
      "Epoch 00005: val_sparse_categorical_crossentropy improved from 6.53212 to 6.44366, saving model to ../model/bestrnnimg_0.hdf5\n",
      "Epoch 6/100\n",
      "1657/1657 [==============================] - 0s 107us/step - loss: 1.2028 - sparse_categorical_crossentropy: 1.2028 - val_loss: 6.5838 - val_sparse_categorical_crossentropy: 6.5838\n",
      "\n",
      "Epoch 00006: val_sparse_categorical_crossentropy did not improve from 6.44366\n",
      "Epoch 7/100\n",
      "1657/1657 [==============================] - 0s 111us/step - loss: 0.7165 - sparse_categorical_crossentropy: 0.7165 - val_loss: 6.7523 - val_sparse_categorical_crossentropy: 6.7523\n",
      "\n",
      "Epoch 00007: val_sparse_categorical_crossentropy did not improve from 6.44366\n",
      "Epoch 8/100\n",
      "1657/1657 [==============================] - 0s 105us/step - loss: 0.4416 - sparse_categorical_crossentropy: 0.4416 - val_loss: 6.9544 - val_sparse_categorical_crossentropy: 6.9544\n",
      "\n",
      "Epoch 00008: val_sparse_categorical_crossentropy did not improve from 6.44366\n",
      "Epoch 9/100\n",
      "1657/1657 [==============================] - 0s 103us/step - loss: 0.2819 - sparse_categorical_crossentropy: 0.2819 - val_loss: 7.3427 - val_sparse_categorical_crossentropy: 7.3427\n",
      "\n",
      "Epoch 00009: val_sparse_categorical_crossentropy did not improve from 6.44366\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "batch_size = 512 * 3\n",
    "steps = (int(train.shape[0]/batch_size))*epochs\n",
    "lr_init, lr_fin = 0.009, 0.0045\n",
    "lr_decay = 0.0001#exp_decay(lr_init, lr_fin, steps)\n",
    "#modelRNN = RNN_model()\n",
    "modelRNN = RNN_model(emb_cols, num_cols)\n",
    "K.set_value(modelRNN.optimizer.lr, lr_init)\n",
    "K.set_value(modelRNN.optimizer.decay, lr_decay)\n",
    "\n",
    "# Fit the NN Model \n",
    "file_path = \"../model/bestrnnimg_{}.hdf5\".format(0)\n",
    "check_point = ModelCheckpoint(file_path, monitor='val_sparse_categorical_crossentropy', mode='min', \n",
    "                              save_best_only=True, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_sparse_categorical_crossentropy', patience=4, mode='min')\n",
    "hist = modelRNN.fit(X_train_final, y_train1, batch_size=batch_size, epochs=100, \n",
    "                    validation_data=(X_test_final, y_test1), verbose=1,\n",
    "                    callbacks=[check_point, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRNN.load_weights(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "158/158 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = modelRNN.predict(X_test, batch_size = batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.zeros(shape=np.argmax(preds,axis = 1).shape)\n",
    "for i in range(preds.shape[0]):\n",
    "    if np.max(preds[i]) > 0.1:\n",
    "        k+=1\n",
    "        classes[i] = np.argmax(preds[i])\n",
    "    else:\n",
    "        classes[i] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'image_top_1':classes}, index=testdex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'region': array([19, 16, 15, 20, 25, 20, 10, 14, 13, 10,  7, 22, 13, 15,  1, 20,  8,\n",
       "        11, 12, 11,  3, 15, 10, 26, 16,  6, 17, 10, 15, 10, 20, 17,  8, 24,\n",
       "        25, 26,  3,  7, 14, 25,  9,  9, 17,  9, 20, 14, 10,  8, 15,  1,  2,\n",
       "        27, 15, 19, 27,  8,  5, 17, 19,  6,  8,  7, 16, 20, 20, 10,  3, 22,\n",
       "         9, 23, 17, 27, 25,  0, 19,  4,  1, 16,  4,  3,  7, 12,  2, 12,  9,\n",
       "        11, 11, 10,  4, 13, 11, 15,  8, 11,  3, 19,  8,  8, 25,  0, 16,  8,\n",
       "        15,  9, 20,  6,  1, 15,  9,  3, 20, 19, 12, 11,  6, 17,  5, 14, 25,\n",
       "         9,  3, 20, 14, 19, 17, 15,  3,  9, 19, 25,  1,  7, 14,  3,  8, 24,\n",
       "        10,  6, 18,  8,  3,  3, 22, 16, 16,  4, 16, 20,  3, 25, 21, 12,  9,\n",
       "         4, 15, 25,  8,  1,  7, 15, 26, 25, 26, 26,  8, 17, 24, 13, 25,  9,\n",
       "         8, 13, 22, 19, 26,  0,  9,  7,  0,  1, 19,  1,  1, 24,  1],\n",
       "       dtype=int8),\n",
       " 'city': array([ 73, 200, 196, 149,  47, 249, 157, 184, 178, 157, 240,  78, 178,\n",
       "        196, 228,  87, 110, 167, 146,  26, 133, 196, 157,  52, 225, 163,\n",
       "        201, 157,   5, 157,  87, 201,  15,  46,  47,  52, 248, 187, 184,\n",
       "         47, 114, 114, 201, 114,  87, 184, 157, 209, 253, 213,  23, 259,\n",
       "        196,  73, 195,  15,  89, 201,  73, 163, 110, 155, 200, 156,  87,\n",
       "        157, 248, 232,  94,  82, 257, 259,  47,  30,  73,  38, 213, 200,\n",
       "         84, 248, 217, 177,  23, 177, 143,  26,  26, 157,  38, 178, 167,\n",
       "        196, 209, 167, 248,  73,  93, 110,  49,  30, 225, 110, 253, 143,\n",
       "        156, 163, 239, 196, 114, 248,  87,  73, 177, 167, 258, 201,  64,\n",
       "        184,  88,  18, 248,  87, 111,  73, 201, 196, 248, 114,  12,  47,\n",
       "        239, 154, 184, 248, 110, 101, 208, 163,  70, 209, 227, 248, 232,\n",
       "        200, 225,  84, 200, 149, 248,  47,  98, 177, 114, 220, 196,  47,\n",
       "         83, 239, 217, 141,  66, 122,  52,  52, 209, 201,  46, 178,  47,\n",
       "        114, 209, 176, 232,  73,  52,  21, 114, 136, 197, 213, 182, 239,\n",
       "        213, 101, 213], dtype=int16),\n",
       " 'parent_category_name': array([4, 2, 0, 4, 6, 4, 2, 4, 4, 4, 5, 4, 4, 0, 3, 4, 6, 4, 4, 5, 6, 4,\n",
       "        3, 4, 2, 4, 4, 4, 2, 3, 5, 6, 4, 4, 8, 4, 4, 4, 4, 4, 5, 2, 2, 4,\n",
       "        4, 4, 4, 5, 4, 3, 0, 2, 4, 4, 4, 4, 4, 4, 4, 7, 7, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 5, 8, 4, 4, 8, 2, 4, 4, 4, 0, 4, 2, 0, 4, 4, 2, 4, 0, 6,\n",
       "        4, 0, 4, 2, 5, 4, 4, 5, 6, 4, 4, 3, 4, 8, 7, 2, 4, 4, 0, 8, 0, 2,\n",
       "        5, 4, 4, 4, 4, 4, 4, 5, 4, 2, 0, 6, 5, 4, 4, 2, 4, 4, 5, 4, 4, 4,\n",
       "        4, 4, 4, 8, 5, 4, 4, 4, 2, 8, 2, 4, 8, 4, 4, 4, 4, 4, 4, 4, 6, 2,\n",
       "        4, 2, 7, 8, 4, 2, 6, 4, 4, 4, 4, 7, 0, 4, 4, 5, 2, 0, 0, 2, 5, 8,\n",
       "        4, 2, 6, 2, 4, 4, 0, 1, 7], dtype=int8),\n",
       " 'category_name': array([41, 22,  2, 41,  0, 41, 37, 28, 28, 10, 15, 28, 41, 43, 38, 28,  0,\n",
       "        41, 28, 15,  0, 10, 42, 41, 22, 28, 28, 10, 37, 12, 19,  0, 41, 28,\n",
       "        17, 28, 10, 10, 10, 28, 15, 32, 22, 41, 41, 21, 10, 15, 28,  1, 40,\n",
       "        22, 10, 45, 10, 41, 10, 10, 10, 33, 33, 28, 10, 28, 10, 41, 28, 10,\n",
       "        10, 15, 39, 10, 10, 24,  4, 28, 28, 10, 43, 10, 37, 14, 28, 28, 22,\n",
       "        10,  2,  0, 10, 40, 28, 37, 15, 28, 41, 11,  0, 10, 10, 20, 28,  3,\n",
       "        33,  4, 10, 10,  2, 16,  2, 36, 15, 28, 10, 28, 10, 45, 10, 11, 41,\n",
       "        22,  2,  0, 15, 28, 10, 37, 28, 10, 11, 28, 10, 10, 10, 45, 28, 17,\n",
       "        11, 41, 21, 28, 37, 39, 32, 28, 17, 10, 10, 28, 28, 28, 28, 10,  0,\n",
       "        22, 10,  4, 33, 17, 41, 22, 23, 41, 28, 45, 28, 33, 43, 41, 41, 18,\n",
       "        37, 14, 14, 37, 15, 16, 28,  4,  0, 22, 28, 28, 31, 27, 33],\n",
       "       dtype=int8),\n",
       " 'param_1': array([119,  59,  31,  18, 136,  18, 140,  61,  61,  46, 141,  61, 159,\n",
       "         95, 103,  61, 136,  68,  61, 127, 136,  46,  17,  68, 154,  61,\n",
       "         61,  51, 151, 137, 127, 136,  44,  99,  62,  61,  51,  51,  46,\n",
       "         99, 127, 158, 154,  42,  44, 124,  51, 127,  61,  17,   3,  59,\n",
       "         46, 176,  51,  68,  51,  51,  46, 134,  85,  61,  51,  61,  46,\n",
       "         68,  61,  51,  51, 127,  65,  46,  46,  54,  47,  61,  61,  51,\n",
       "         82,  46,  71,  67,  99,  61,  59,  46, 155, 136,  51,   1,  99,\n",
       "         74, 127,  61,  44, 127, 136,  51,  51, 174,  61, 146, 161,  48,\n",
       "         46,  51, 155,  80,  32,  17, 127,  20,  46,  61,  51,  24,  51,\n",
       "        127,  44,  59, 101, 136, 127,  61,  51, 151,  61,  46, 127,  99,\n",
       "         51,  51,  51, 172,  61,  59, 127,  68, 124,  99,  74, 169, 120,\n",
       "         61,  76,  46,  51,  61,  61,  61,  61,  46, 136,  86,  46,  47,\n",
       "        161,  91,  42,  59,  96,  30,  61,  24,  61, 134,  82,  68,  44,\n",
       "        127, 151,  67,  67, 121, 127, 168,  61,  49, 136,  88,  61,  61,\n",
       "        116, 128, 161], dtype=int16),\n",
       " 'price': array([0.33130129, 0.44255043, 0.45844678, 0.42541411, 0.58570398,\n",
       "        0.396353  , 0.51435168, 0.34360742, 0.34360742, 0.33130129,\n",
       "        0.54157014, 0.03831198, 0.23560903, 0.43247675, 0.47077769,\n",
       "        0.36954432, 0.65494637, 0.34360742, 0.38186422, 0.79448614,\n",
       "        0.68677265, 0.396353  , 0.        , 0.40425687, 0.38186422,\n",
       "        0.40425687, 0.38186422, 0.29312696, 0.        , 0.2694644 ,\n",
       "        0.75779444, 0.61253869, 0.50326124, 0.45844678, 0.36954432,\n",
       "        0.38186422, 0.31544632, 0.34360742, 0.34360742, 0.33130129,\n",
       "        0.80965496, 0.32394038, 0.3536664 , 0.34360742, 0.42014858,\n",
       "        0.47077769, 0.36217356, 0.81084366, 0.31544632, 0.5314934 ,\n",
       "        0.45262475, 0.40425687, 0.34360742, 0.40606808, 0.34360742,\n",
       "        0.29312696, 0.27731764, 0.36217356, 0.41117063, 0.38186422,\n",
       "        0.34360742, 0.38186422, 0.34360742, 0.42014858, 0.34360742,\n",
       "        0.40425687, 0.34360742, 0.34360742, 0.32990545, 0.80669323,\n",
       "        0.47659462, 0.25508929, 0.31544632, 0.42014858, 0.47992443,\n",
       "        0.38186422, 0.39193239, 0.33130129, 0.65885175, 0.34886542,\n",
       "        0.31544632, 0.44255043, 0.34360742, 0.50010231, 0.51916059,\n",
       "        0.34360742, 0.396353  , 0.7469752 , 0.34360742, 0.44236594,\n",
       "        0.42786996, 0.5314934 , 0.78580753, 0.35357436, 0.30540566,\n",
       "        0.6869942 , 0.60527952, 0.396353  , 0.27731764, 0.        ,\n",
       "        0.34360742, 0.42014858, 0.03831198, 0.34360742, 0.31544632,\n",
       "        0.39193239, 0.43247675, 0.20525845, 0.45844678, 0.25508929,\n",
       "        0.77323283, 0.25508929, 0.25508929, 0.38186422, 0.32394038,\n",
       "        0.30540566, 0.40425687, 0.79791879, 0.44255043, 0.64008845,\n",
       "        0.34360742, 0.69707151, 0.78602903, 0.32394038, 0.34360742,\n",
       "        0.41673034, 0.42014858, 0.35808348, 0.87644134, 0.3536664 ,\n",
       "        0.33779614, 0.40425687, 0.31544632, 0.30540566, 0.37604682,\n",
       "        0.38186422, 0.7512843 , 0.34360742, 0.47077769, 0.47294511,\n",
       "        0.        , 0.45844678, 0.25508929, 0.33130129, 0.34360742,\n",
       "        0.32394038, 0.33779614, 0.43247675, 0.36217356, 0.33130129,\n",
       "        0.38186422, 0.27731764, 0.66232689, 0.54308445, 0.33130129,\n",
       "        0.        , 0.32394038, 0.21732187, 0.44255043, 0.47077769,\n",
       "        0.56980351, 0.40056434, 0.40425687, 0.34360742, 0.39193239,\n",
       "        0.        , 0.46495539, 0.36598171, 0.45106811, 0.84675206,\n",
       "        0.03831198, 0.48937221, 0.49675184, 0.21040379, 0.8040978 ,\n",
       "        0.36954432, 0.50908417, 0.40425687, 0.64642611, 0.42014858,\n",
       "        0.34360742, 0.50908417, 0.43247675, 0.55009003, 0.        ]),\n",
       " 'item_seq_number': array([0.06147745, 0.26115174, 0.1948789 , 0.50164806, 0.09743945,\n",
       "        0.1948789 , 0.42823863, 0.36460659, 0.39403299, 0.43571912,\n",
       "        0.15891689, 0.12295489, 0.24018566, 0.34148194, 0.15891689,\n",
       "        0.39507035, 0.47036712, 0.1948789 , 0.12295489, 0.54399075,\n",
       "        0.22039434, 0.36164988, 0.508795  , 0.50850843, 0.36164988,\n",
       "        0.18443234, 0.22039434, 0.2657011 , 0.18443234, 0.25635634,\n",
       "        0.52801225, 0.        , 0.37292768, 0.388656  , 0.50439609,\n",
       "        0.21267702, 0.3702398 , 0.22749359, 0.38174134, 0.67685615,\n",
       "        0.82301146, 0.22749359, 0.47168112, 0.18443234, 0.29554391,\n",
       "        0.        , 0.43374075, 0.26115174, 0.25635634, 0.21267702,\n",
       "        0.53740307, 0.12295489, 0.29554391, 0.39710936, 0.12295489,\n",
       "        0.15891689, 0.30738723, 0.38975779, 0.43829012, 0.45013344,\n",
       "        0.06147745, 0.2657011 , 0.38410663, 0.27002846, 0.1948789 ,\n",
       "        0.51049524, 0.28549242, 0.52472694, 0.34696987, 0.89292798,\n",
       "        0.09743945, 0.51905061, 0.20422366, 0.32026389, 0.44201206,\n",
       "        0.35702135, 0.37553649, 0.35702135, 0.25128678, 0.29865627,\n",
       "        0.55433035, 0.18443234, 0.17258901, 0.        , 0.25635634,\n",
       "        0.388656  , 0.09743945, 0.17258901, 0.43103235, 0.96715067,\n",
       "        0.14274621, 0.12295489, 0.92299684, 0.32262918, 0.30166311,\n",
       "        0.25635634, 0.14274621, 0.2657011 , 0.17258901, 0.25635634,\n",
       "        0.32262918, 0.14274621, 0.22749359, 0.24018566, 0.27002846,\n",
       "        0.41444818, 0.45339859, 0.56602373, 0.27809704, 0.18443234,\n",
       "        0.44616568, 0.5966775 , 0.48609545, 0.25635634, 0.35542323,\n",
       "        0.75304422, 0.44788793, 0.2657011 , 0.22749359, 0.14274621,\n",
       "        0.32493303, 0.        , 0.24018566, 0.4544608 , 0.39192115,\n",
       "        0.41527324, 0.25635634, 0.40201079, 0.14274621, 0.32936862,\n",
       "        0.36460659, 0.15891689, 0.31783379, 0.5412555 , 0.54664416,\n",
       "        0.36314055, 0.        , 0.31533522, 0.25635634, 0.34517803,\n",
       "        0.12295489, 0.34517803, 0.21267702, 0.06147745, 0.35213793,\n",
       "        0.36314055, 0.80168372, 0.12295489, 0.41609069, 0.5182827 ,\n",
       "        0.09743945, 0.31533522, 0.06147745, 0.1948789 , 0.47837813,\n",
       "        0.30738723, 0.        , 0.34334924, 0.34696987, 0.34696987,\n",
       "        0.22039434, 0.65878998, 0.37292768, 0.48609545, 0.39609572,\n",
       "        0.        , 0.17258901, 0.43506455, 0.25128678, 0.51188763,\n",
       "        0.1948789 , 0.        , 0.22749359, 0.40295939, 0.29554391,\n",
       "        0.33957449, 0.39609572, 0.22039434, 0.        , 0.31783379,\n",
       "        0.        , 0.46992476, 0.45232351, 0.46348823, 0.        ]),\n",
       " 'user_type': array([1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 2, 1, 0, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "        1, 0, 0, 2, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 2, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 1, 2, 0, 1], dtype=int8),\n",
       " 'image_top_1': array([0.32898172, 0.22584856, 0.98955614, 0.25979112, 0.73890339,\n",
       "        0.25979112, 0.92167102, 0.18505222, 0.13544386, 0.01501305,\n",
       "        0.45561358, 0.03883812, 0.33942559, 0.92950392, 0.69582245,\n",
       "        0.13315927, 0.36488251, 0.32082245, 0.03100522, 0.65633159,\n",
       "        0.73890339, 0.02839426, 0.27513055, 0.31233681, 0.46344648,\n",
       "        0.14229765, 0.20169713, 0.02056136, 0.41840731, 0.71671018,\n",
       "        0.72454308, 0.3694517 , 0.3270235 , 0.14490862, 0.78851175,\n",
       "        0.14197128, 0.21475196, 0.01370757, 0.03394256, 0.20626632,\n",
       "        0.72389034, 0.54275457, 0.4631201 , 0.28785901, 0.3270235 ,\n",
       "        0.33909922, 0.01533943, 0.72454308, 0.12336815, 0.65861619,\n",
       "        0.95953003, 0.46964752, 0.03035248, 0.00359008, 0.01436031,\n",
       "        0.2712141 , 0.01436031, 0.01370757, 0.01664491, 0.44810705,\n",
       "        0.74281984, 0.16155352, 0.01468668, 0.17624021, 0.03035248,\n",
       "        0.2823107 , 0.095953  , 0.02806789, 0.01370757, 0.72389034,\n",
       "        0.86096606, 0.02839426, 0.01697128, 1.        , 0.65045692,\n",
       "        0.13740209, 0.36586162, 0.02317232, 0.25685379, 0.03100522,\n",
       "        0.90208877, 0.94516971, 0.20398172, 0.18276762, 0.46899478,\n",
       "        0.02872063, 0.98629243, 0.73825065, 0.01533943, 0.95496084,\n",
       "        0.14523499, 0.3906658 , 0.38870757, 0.14686684, 0.85248042,\n",
       "        0.4308094 , 0.3616188 , 0.01533943, 0.03557441, 0.67232376,\n",
       "        0.17232376, 0.79112272, 0.34399478, 0.62695822, 0.03590078,\n",
       "        0.01729765, 0.6227154 , 0.74608355, 0.97845953, 0.56560052,\n",
       "        0.46409922, 0.77415144, 0.03818538, 0.16351175, 0.02056136,\n",
       "        0.27774151, 0.01697128, 0.46083551, 0.3270235 , 0.48629243,\n",
       "        0.99738903, 0.34432115, 0.56331593, 0.18929504, 0.01468668,\n",
       "        0.49347258, 0.14686684, 0.01370757, 0.33028721, 0.01533943,\n",
       "        0.01533943, 0.2075718 , 0.02741514, 0.01240209, 0.18668407,\n",
       "        0.30254569, 0.49477807, 0.74281984, 0.24347258, 0.15110966,\n",
       "        0.40763708, 0.87206266, 0.83028721, 0.19875979, 0.50979112,\n",
       "        0.02610966, 0.2176893 , 0.12924282, 0.17460836, 0.17069191,\n",
       "        0.17330287, 0.03524804, 0.73825065, 0.26729765, 0.20430809,\n",
       "        0.64980418, 0.39262402, 0.81201044, 0.26860313, 0.45789817,\n",
       "        0.37173629, 0.27088773, 0.03133159, 0.1093342 , 0.19353786,\n",
       "        0.46638381, 0.93472585, 0.32571802, 0.3270235 , 0.72454308,\n",
       "        0.70104439, 0.9464752 , 0.9464752 , 0.41873368, 0.72454308,\n",
       "        0.74543081, 0.21214099, 0.595953  , 0.36488251, 0.55091384,\n",
       "        0.16351175, 0.12956919, 0.91644909, 0.40600522, 0.34497389]),\n",
       " 'avg_days_up_user': array([0.73337679, 0.        , 0.53715776, 0.94589309, 0.        ,\n",
       "        0.53715776, 0.69426336, 0.82920469, 0.88070404, 0.92568449,\n",
       "        0.        , 0.        , 0.        , 0.8559322 , 0.76857888,\n",
       "        0.88070404, 0.46284224, 0.        , 0.53715776, 0.88070404,\n",
       "        0.        , 0.8559322 , 0.92568449, 0.80052151, 0.94589309,\n",
       "        0.88070404, 0.64960887, 0.88070404, 0.        , 0.76857888,\n",
       "        0.76857888, 0.        , 0.82920469, 0.94589309, 0.92568449,\n",
       "        0.59810952, 0.80052151, 0.80052151, 0.64960887, 0.76857888,\n",
       "        0.82920469, 0.80052151, 0.94589309, 0.94589309, 0.92568449,\n",
       "        0.        , 0.        , 0.        , 0.59810952, 0.73337679,\n",
       "        0.69426336, 1.        , 0.46284224, 0.69426336, 0.        ,\n",
       "        0.        , 0.        , 0.82920469, 0.96479791, 0.88070404,\n",
       "        0.80052151, 0.64960887, 0.96479791, 0.88070404, 0.69426336,\n",
       "        0.9041721 , 0.80052151, 0.73337679, 0.64960887, 0.73337679,\n",
       "        0.69426336, 0.92568449, 0.46284224, 0.3666884 , 0.46284224,\n",
       "        0.82920469, 0.94589309, 0.9041721 , 1.        , 0.8559322 ,\n",
       "        0.64960887, 0.        , 0.        , 0.        , 0.23142112,\n",
       "        0.82920469, 0.        , 0.64960887, 0.9041721 , 0.73337679,\n",
       "        0.23142112, 0.        , 0.80052151, 0.76857888, 0.64960887,\n",
       "        0.46284224, 0.59810952, 0.88070404, 0.23142112, 0.88070404,\n",
       "        0.82920469, 0.80052151, 0.94589309, 0.8559322 , 0.        ,\n",
       "        0.69426336, 0.82920469, 0.82920469, 0.96479791, 0.59810952,\n",
       "        0.80052151, 0.94589309, 0.94589309, 0.80052151, 0.88070404,\n",
       "        0.80052151, 0.94589309, 0.        , 0.        , 1.        ,\n",
       "        0.76857888, 0.        , 0.46284224, 0.94589309, 0.94589309,\n",
       "        0.64960887, 0.94589309, 0.76857888, 0.73337679, 0.9041721 ,\n",
       "        0.64960887, 0.        , 0.64960887, 0.82920469, 0.96479791,\n",
       "        0.80052151, 0.        , 0.76857888, 0.        , 0.82920469,\n",
       "        0.88070404, 0.80052151, 0.98305085, 0.        , 0.80052151,\n",
       "        0.80052151, 0.8559322 , 0.88070404, 0.8559322 , 0.92568449,\n",
       "        0.3666884 , 0.        , 0.        , 0.88070404, 0.92568449,\n",
       "        0.59810952, 0.        , 0.8559322 , 0.        , 0.88070404,\n",
       "        0.        , 0.8559322 , 0.64960887, 0.73337679, 0.82920469,\n",
       "        0.64960887, 0.        , 0.80052151, 0.        , 0.73337679,\n",
       "        0.82920469, 0.        , 0.64960887, 0.9041721 , 0.82920469,\n",
       "        0.94589309, 0.        , 0.80052151, 0.64960887, 0.88070404,\n",
       "        0.        , 0.92568449, 0.59810952, 0.88070404, 0.        ]),\n",
       " 'avg_times_up_user': array([0.68264563, 0.        , 0.43082524, 0.68264563, 0.        ,\n",
       "        0.43082524, 0.43082524, 0.43082524, 0.43082524, 0.68264563,\n",
       "        0.        , 0.        , 0.        , 0.43082524, 0.43082524,\n",
       "        0.43082524, 0.43082524, 0.        , 0.43082524, 0.43082524,\n",
       "        0.        , 0.43082524, 0.68264563, 0.43082524, 0.68264563,\n",
       "        0.43082524, 0.43082524, 0.43082524, 0.        , 0.43082524,\n",
       "        0.43082524, 0.        , 0.43082524, 0.68264563, 0.68264563,\n",
       "        0.43082524, 0.68264563, 0.43082524, 0.43082524, 0.43082524,\n",
       "        0.43082524, 0.68264563, 0.68264563, 0.86165049, 0.68264563,\n",
       "        0.        , 0.        , 0.        , 0.43082524, 0.43082524,\n",
       "        0.43082524, 0.68264563, 0.43082524, 0.43082524, 0.        ,\n",
       "        0.        , 0.        , 0.43082524, 0.68264563, 0.43082524,\n",
       "        0.43082524, 0.43082524, 0.68264563, 0.68264563, 0.43082524,\n",
       "        0.68264563, 0.43082524, 0.43082524, 0.43082524, 0.43082524,\n",
       "        0.43082524, 0.68264563, 0.43082524, 0.43082524, 0.43082524,\n",
       "        0.43082524, 0.68264563, 0.43082524, 0.68264563, 0.43082524,\n",
       "        0.43082524, 0.        , 0.        , 0.        , 0.43082524,\n",
       "        0.43082524, 0.        , 0.43082524, 0.68264563, 0.43082524,\n",
       "        0.43082524, 0.        , 0.43082524, 0.43082524, 0.43082524,\n",
       "        0.43082524, 0.43082524, 0.43082524, 0.43082524, 0.43082524,\n",
       "        0.43082524, 0.43082524, 0.86165049, 0.43082524, 0.        ,\n",
       "        0.43082524, 0.43082524, 0.43082524, 0.86165049, 0.43082524,\n",
       "        0.43082524, 0.68264563, 0.68264563, 0.68264563, 0.68264563,\n",
       "        0.43082524, 0.68264563, 0.        , 0.        , 0.68264563,\n",
       "        0.43082524, 0.        , 0.68264563, 0.68264563, 0.68264563,\n",
       "        0.43082524, 0.68264563, 0.43082524, 0.43082524, 0.86165049,\n",
       "        0.43082524, 0.        , 0.43082524, 0.43082524, 0.68264563,\n",
       "        0.43082524, 0.        , 0.43082524, 0.        , 0.43082524,\n",
       "        0.43082524, 0.43082524, 0.68264563, 0.        , 0.43082524,\n",
       "        0.43082524, 0.43082524, 0.43082524, 0.43082524, 0.68264563,\n",
       "        0.43082524, 0.        , 0.        , 0.43082524, 0.68264563,\n",
       "        0.43082524, 0.        , 0.68264563, 0.        , 0.43082524,\n",
       "        0.        , 0.43082524, 0.43082524, 0.43082524, 0.43082524,\n",
       "        0.43082524, 0.        , 0.43082524, 0.        , 0.43082524,\n",
       "        0.43082524, 0.        , 0.43082524, 0.68264563, 0.43082524,\n",
       "        0.68264563, 0.        , 0.43082524, 0.43082524, 0.43082524,\n",
       "        0.        , 0.68264563, 0.43082524, 0.68264563, 0.        ]),\n",
       " 'n_user_items': array([0.05053127, 0.        , 0.20057692, 0.34937005, 0.        ,\n",
       "        0.05053127, 0.22329882, 0.3096826 , 0.37018922, 0.47982637,\n",
       "        0.        , 0.212455  , 0.20057692, 0.20057692, 0.13691505,\n",
       "        0.30437859, 0.05053127, 0.08638378, 0.08638378, 0.29883877,\n",
       "        0.        , 0.37334447, 0.15612615, 0.25110819, 0.36695201,\n",
       "        0.05053127, 0.11419314, 0.25915133, 0.08638378, 0.18744632,\n",
       "        0.37942497, 0.        , 0.31965794, 0.2869607 , 0.48753762,\n",
       "        0.11419314, 0.3455351 , 0.15612615, 0.24250993, 0.46127642,\n",
       "        0.52023489, 0.25110819, 0.44129364, 0.17276755, 0.212455  ,\n",
       "        0.        , 0.13691505, 0.        , 0.15612615, 0.15612615,\n",
       "        0.24250993, 0.05053127, 0.18744632, 0.17276755, 0.08638378,\n",
       "        0.17276755, 0.20057692, 0.2667067 , 0.15612615, 0.05053127,\n",
       "        0.05053127, 0.25915133, 0.212455  , 0.13691505, 0.31965794,\n",
       "        0.38235747, 0.30437859, 0.44308682, 0.2738301 , 0.7561359 ,\n",
       "        0.08638378, 0.38235747, 0.17276755, 0.08638378, 0.30437859,\n",
       "        0.3096826 , 0.35670307, 0.31477006, 0.13691505, 0.20057692,\n",
       "        0.32436137, 0.        , 0.17276755, 0.17276755, 0.05053127,\n",
       "        0.20057692, 0.08638378, 0.05053127, 0.33749197, 0.94958092,\n",
       "        0.05053127, 0.05053127, 0.94714113, 0.37642179, 0.25915133,\n",
       "        0.17276755, 0.11419314, 0.15612615, 0.15612615, 0.20057692,\n",
       "        0.36021387, 0.08638378, 0.08638378, 0.212455  , 0.29883877,\n",
       "        0.3096826 , 0.39076236, 0.37942497, 0.05053127, 0.20057692,\n",
       "        0.23327417, 0.41527745, 0.37942497, 0.25915133, 0.36362846,\n",
       "        0.62235807, 0.23327417, 0.05053127, 0.        , 0.08638378,\n",
       "        0.22329882, 0.        , 0.05053127, 0.33326695, 0.37642179,\n",
       "        0.57699871, 0.17276755, 0.37334447, 0.08638378, 0.20057692,\n",
       "        0.13691505, 0.        , 0.18744632, 0.45001227, 0.29883877,\n",
       "        0.11419314, 0.        , 0.18744632, 0.08638378, 0.29883877,\n",
       "        0.05053127, 0.212455  , 0.11419314, 0.2869607 , 0.28056824,\n",
       "        0.2869607 , 0.78211233, 0.11419314, 0.25915133, 0.46874122,\n",
       "        0.05053127, 0.30437859, 0.        , 0.15612615, 0.37942497,\n",
       "        0.20057692, 0.        , 0.45972825, 0.        , 0.17276755,\n",
       "        0.        , 0.68610439, 0.212455  , 0.46874122, 0.212455  ,\n",
       "        0.08638378, 0.        , 0.39606638, 0.        , 0.35670307,\n",
       "        0.15612615, 0.        , 0.15612615, 0.3455351 , 0.22329882,\n",
       "        0.2738301 , 0.        , 0.212455  , 0.05053127, 0.08638378,\n",
       "        0.08638378, 0.3455351 , 0.37942497, 0.15612615, 0.        ]),\n",
       " 'param123': array([323, 174,  39,  19, 409,  19, 428, 189, 215,  77, 431, 192, 456,\n",
       "        272, 306, 211, 372, 237, 183, 333, 377,  77,  18, 237, 451, 200,\n",
       "        213, 134, 448, 425, 338, 366,  51, 287, 231, 200, 121, 137, 106,\n",
       "        300, 331, 455, 451,  50,  51, 328, 141, 333, 214,  18,   3, 174,\n",
       "         87, 477, 153, 237, 142, 131,  59, 359, 261, 201, 152, 182,  73,\n",
       "        237, 193, 156, 135, 331, 234,  75,  65, 169, 108, 204, 191, 123,\n",
       "        257,  60, 240, 236, 297, 221, 174,  82, 452, 367, 141,   1, 288,\n",
       "        243, 332, 200,  51, 341, 406, 141, 136, 475, 181, 443, 462, 112,\n",
       "        105, 131, 452, 251,  40,  18, 331,  21,  55, 201, 134,  32, 131,\n",
       "        343,  51, 174, 304, 420, 331, 180, 142, 448, 203,  68, 343, 292,\n",
       "        149, 143, 137, 473, 213, 174, 342, 237, 328, 292, 243, 470, 324,\n",
       "        193, 245,  95, 124, 211, 211, 185, 183,  95, 399, 263, 100, 108,\n",
       "        461, 268,  50, 174, 273,  38, 184,  32, 205, 357, 253, 237,  51,\n",
       "        348, 448, 236, 236, 325, 332, 469, 181, 114, 419, 265, 202, 222,\n",
       "        320, 349, 460], dtype=int16),\n",
       " 'reg_dense': array([0.30874337, 0.87044722, 0.61041628, 0.8065962 , 0.3214673 ,\n",
       "        0.8065962 , 0.61967005, 0.22499675, 0.22499675, 0.61967005,\n",
       "        0.02456587, 0.01716285, 0.22499675, 0.61041628, 0.4019751 ,\n",
       "        0.8065962 , 1.        , 0.2035974 , 0.19168317, 0.2035974 ,\n",
       "        0.56784893, 0.61041628, 0.61967005, 0.64187909, 0.87044722,\n",
       "        0.41053484, 0.35478087, 0.61967005, 0.61041628, 0.61967005,\n",
       "        0.8065962 , 0.35478087, 1.        , 0.71914807, 0.3214673 ,\n",
       "        0.64187909, 0.56784893, 0.02456587, 0.22499675, 0.3214673 ,\n",
       "        0.        , 0.        , 0.35478087, 0.        , 0.8065962 ,\n",
       "        0.22499675, 0.61967005, 1.        , 0.61041628, 0.4019751 ,\n",
       "        0.81955148, 0.49983372, 0.61041628, 0.30874337, 0.49983372,\n",
       "        1.        , 0.90561154, 0.35478087, 0.30874337, 0.41053484,\n",
       "        1.        , 0.02456587, 0.87044722, 0.8065962 , 0.8065962 ,\n",
       "        0.61967005, 0.56784893, 0.01716285, 0.        , 0.5169532 ,\n",
       "        0.35478087, 0.49983372, 0.3214673 , 0.19399662, 0.30874337,\n",
       "        0.02887465, 0.4019751 , 0.87044722, 0.02887465, 0.56784893,\n",
       "        0.02456587, 0.19168317, 0.81955148, 0.19168317, 0.        ,\n",
       "        0.2035974 , 0.2035974 , 0.61967005, 0.02887465, 0.22499675,\n",
       "        0.2035974 , 0.61041628, 1.        , 0.2035974 , 0.56784893,\n",
       "        0.30874337, 1.        , 1.        , 0.3214673 , 0.19399662,\n",
       "        0.87044722, 1.        , 0.61041628, 0.        , 0.8065962 ,\n",
       "        0.41053484, 0.4019751 , 0.61041628, 0.        , 0.56784893,\n",
       "        0.8065962 , 0.30874337, 0.19168317, 0.2035974 , 0.41053484,\n",
       "        0.35478087, 0.90561154, 0.22499675, 0.3214673 , 0.        ,\n",
       "        0.56784893, 0.8065962 , 0.22499675, 0.30874337, 0.35478087,\n",
       "        0.61041628, 0.56784893, 0.        , 0.30874337, 0.3214673 ,\n",
       "        0.4019751 , 0.02456587, 0.22499675, 0.56784893, 1.        ,\n",
       "        0.71914807, 0.61967005, 0.41053484, 0.60255057, 1.        ,\n",
       "        0.56784893, 0.56784893, 0.01716285, 0.87044722, 0.87044722,\n",
       "        0.02887465, 0.87044722, 0.8065962 , 0.56784893, 0.3214673 ,\n",
       "        0.87738755, 0.19168317, 0.        , 0.02887465, 0.61041628,\n",
       "        0.3214673 , 1.        , 0.4019751 , 0.02456587, 0.61041628,\n",
       "        0.64187909, 0.3214673 , 0.64187909, 0.64187909, 1.        ,\n",
       "        0.35478087, 0.71914807, 0.22499675, 0.3214673 , 0.        ,\n",
       "        1.        , 0.22499675, 0.01716285, 0.30874337, 0.64187909,\n",
       "        0.19399662, 0.        , 0.02456587, 0.19399662, 0.4019751 ,\n",
       "        0.30874337, 0.4019751 , 0.4019751 , 0.71914807, 0.4019751 ]),\n",
       " 'rural': array([0.19676113, 0.29271255, 0.62995951, 0.41700405, 0.40161943,\n",
       "        0.41700405, 0.32631579, 0.42753036, 0.8242915 , 0.32631579,\n",
       "        0.        , 0.34736842, 0.8242915 , 0.62995951, 0.80566802,\n",
       "        0.41700405, 1.        , 0.36801619, 0.51821862, 0.36801619,\n",
       "        0.24615385, 0.62995951, 0.32631579, 0.72064777, 0.29271255,\n",
       "        0.15809717, 0.44048583, 0.32631579, 0.62995951, 0.32631579,\n",
       "        0.41700405, 0.44048583, 1.        , 0.36032389, 0.40161943,\n",
       "        0.72064777, 0.24615385, 0.        , 0.42753036, 0.40161943,\n",
       "        0.39392713, 0.39392713, 0.44048583, 0.39392713, 0.41700405,\n",
       "        0.42753036, 0.32631579, 1.        , 0.62995951, 0.80566802,\n",
       "        0.6582996 , 0.24089069, 0.62995951, 0.19676113, 0.24089069,\n",
       "        1.        , 0.36032389, 0.44048583, 0.19676113, 0.15809717,\n",
       "        1.        , 0.        , 0.29271255, 0.41700405, 0.41700405,\n",
       "        0.32631579, 0.24615385, 0.34736842, 0.39392713, 0.57773279,\n",
       "        0.44048583, 0.24089069, 0.40161943, 0.95384615, 0.19676113,\n",
       "        0.30850202, 0.80566802, 0.29271255, 0.30850202, 0.24615385,\n",
       "        0.        , 0.51821862, 0.6582996 , 0.51821862, 0.39392713,\n",
       "        0.36801619, 0.36801619, 0.32631579, 0.30850202, 0.8242915 ,\n",
       "        0.36801619, 0.62995951, 1.        , 0.36801619, 0.24615385,\n",
       "        0.19676113, 1.        , 1.        , 0.40161943, 0.95384615,\n",
       "        0.29271255, 1.        , 0.62995951, 0.39392713, 0.41700405,\n",
       "        0.15809717, 0.80566802, 0.62995951, 0.39392713, 0.24615385,\n",
       "        0.41700405, 0.19676113, 0.51821862, 0.36801619, 0.15809717,\n",
       "        0.44048583, 0.36032389, 0.42753036, 0.40161943, 0.39392713,\n",
       "        0.24615385, 0.41700405, 0.42753036, 0.19676113, 0.44048583,\n",
       "        0.62995951, 0.24615385, 0.39392713, 0.19676113, 0.40161943,\n",
       "        0.80566802, 0.        , 0.42753036, 0.24615385, 1.        ,\n",
       "        0.36032389, 0.32631579, 0.15809717, 0.88906883, 1.        ,\n",
       "        0.24615385, 0.24615385, 0.34736842, 0.29271255, 0.29271255,\n",
       "        0.30850202, 0.29271255, 0.41700405, 0.24615385, 0.40161943,\n",
       "        0.31336032, 0.51821862, 0.39392713, 0.30850202, 0.62995951,\n",
       "        0.40161943, 1.        , 0.80566802, 0.        , 0.62995951,\n",
       "        0.72064777, 0.40161943, 0.72064777, 0.72064777, 1.        ,\n",
       "        0.44048583, 0.36032389, 0.8242915 , 0.40161943, 0.39392713,\n",
       "        1.        , 0.8242915 , 0.34736842, 0.19676113, 0.72064777,\n",
       "        0.95384615, 0.39392713, 0.        , 0.95384615, 0.80566802,\n",
       "        0.19676113, 0.80566802, 0.80566802, 0.36032389, 0.80566802]),\n",
       " 'reg_Time_zone': array([6, 4, 2, 2, 2, 2, 2, 6, 6, 2, 6, 6, 6, 2, 6, 2, 2, 1, 3, 1, 6, 2,\n",
       "        2, 2, 4, 1, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 6, 6, 6, 2, 1, 1, 4, 1,\n",
       "        2, 6, 2, 2, 2, 6, 2, 2, 2, 6, 2, 2, 5, 4, 6, 1, 2, 6, 4, 2, 2, 2,\n",
       "        6, 6, 1, 4, 4, 2, 2, 1, 6, 0, 6, 4, 0, 6, 6, 3, 2, 3, 1, 1, 1, 2,\n",
       "        0, 6, 1, 2, 2, 1, 6, 6, 2, 2, 2, 1, 4, 2, 2, 1, 2, 1, 6, 2, 1, 6,\n",
       "        2, 6, 3, 1, 1, 4, 5, 6, 2, 1, 6, 2, 6, 6, 4, 2, 6, 1, 6, 2, 6, 6,\n",
       "        6, 6, 2, 2, 2, 1, 2, 2, 6, 6, 6, 4, 4, 0, 4, 2, 6, 2, 2, 3, 1, 0,\n",
       "        2, 2, 2, 6, 6, 2, 2, 2, 2, 2, 2, 4, 2, 6, 2, 1, 2, 6, 6, 6, 2, 1,\n",
       "        1, 6, 1, 6, 6, 6, 6, 2, 6], dtype=int8),\n",
       " 'reg_Population': array([0.73054399, 0.48820255, 0.71432351, 0.6239931 , 0.34853771,\n",
       "        0.6239931 , 0.50303213, 0.36289375, 0.23220193, 0.50303213,\n",
       "        0.12351076, 0.58528843, 0.23220193, 0.71432351, 0.67419561,\n",
       "        0.6239931 , 1.        , 0.38710174, 0.22017736, 0.38710174,\n",
       "        0.54539688, 0.71432351, 0.50303213, 0.29688071, 0.48820255,\n",
       "        0.38236371, 0.33279794, 0.50303213, 0.71432351, 0.50303213,\n",
       "        0.6239931 , 0.33279794, 1.        , 0.09770201, 0.34853771,\n",
       "        0.29688071, 0.54539688, 0.12351076, 0.36289375, 0.34853771,\n",
       "        0.41138179, 0.41138179, 0.33279794, 0.41138179, 0.6239931 ,\n",
       "        0.36289375, 0.50303213, 1.        , 0.71432351, 0.67419561,\n",
       "        0.12541123, 0.06713374, 0.71432351, 0.73054399, 0.06713374,\n",
       "        1.        , 0.        , 0.33279794, 0.73054399, 0.38236371,\n",
       "        1.        , 0.12351076, 0.48820255, 0.6239931 , 0.6239931 ,\n",
       "        0.50303213, 0.54539688, 0.58528843, 0.41138179, 0.12116193,\n",
       "        0.33279794, 0.06713374, 0.34853771, 0.3098018 , 0.73054399,\n",
       "        0.31507002, 0.67419561, 0.48820255, 0.31507002, 0.54539688,\n",
       "        0.12351076, 0.22017736, 0.12541123, 0.22017736, 0.41138179,\n",
       "        0.38710174, 0.38710174, 0.50303213, 0.31507002, 0.23220193,\n",
       "        0.38710174, 0.71432351, 1.        , 0.38710174, 0.54539688,\n",
       "        0.73054399, 1.        , 1.        , 0.34853771, 0.3098018 ,\n",
       "        0.48820255, 1.        , 0.71432351, 0.41138179, 0.6239931 ,\n",
       "        0.38236371, 0.67419561, 0.71432351, 0.41138179, 0.54539688,\n",
       "        0.6239931 , 0.73054399, 0.22017736, 0.38710174, 0.38236371,\n",
       "        0.33279794, 0.        , 0.36289375, 0.34853771, 0.41138179,\n",
       "        0.54539688, 0.6239931 , 0.36289375, 0.73054399, 0.33279794,\n",
       "        0.71432351, 0.54539688, 0.41138179, 0.73054399, 0.34853771,\n",
       "        0.67419561, 0.12351076, 0.36289375, 0.54539688, 1.        ,\n",
       "        0.09770201, 0.50303213, 0.38236371, 0.39855576, 1.        ,\n",
       "        0.54539688, 0.54539688, 0.58528843, 0.48820255, 0.48820255,\n",
       "        0.31507002, 0.48820255, 0.6239931 , 0.54539688, 0.34853771,\n",
       "        0.12821625, 0.22017736, 0.41138179, 0.31507002, 0.71432351,\n",
       "        0.34853771, 1.        , 0.67419561, 0.12351076, 0.71432351,\n",
       "        0.29688071, 0.34853771, 0.29688071, 0.29688071, 1.        ,\n",
       "        0.33279794, 0.09770201, 0.23220193, 0.34853771, 0.41138179,\n",
       "        1.        , 0.23220193, 0.58528843, 0.73054399, 0.29688071,\n",
       "        0.3098018 , 0.41138179, 0.12351076, 0.3098018 , 0.67419561,\n",
       "        0.73054399, 0.67419561, 0.67419561, 0.09770201, 0.67419561]),\n",
       " 'reg_Urban': array([0.80242915, 0.70688259, 0.37004049, 0.58218623, 0.59838057,\n",
       "        0.58218623, 0.67287449, 0.57246964, 0.1757085 , 0.67287449,\n",
       "        1.        , 0.6534413 , 0.1757085 , 0.37004049, 0.19433198,\n",
       "        0.58218623, 0.        , 0.63238866, 0.48178138, 0.63238866,\n",
       "        0.75384615, 0.37004049, 0.67287449, 0.27935223, 0.70688259,\n",
       "        0.84129555, 0.55951417, 0.67287449, 0.37004049, 0.67287449,\n",
       "        0.58218623, 0.55951417, 0.        , 0.64048583, 0.59838057,\n",
       "        0.27935223, 0.75384615, 1.        , 0.57246964, 0.59838057,\n",
       "        0.60647773, 0.60647773, 0.55951417, 0.60647773, 0.58218623,\n",
       "        0.57246964, 0.67287449, 0.        , 0.37004049, 0.19433198,\n",
       "        0.34251012, 0.75870445, 0.37004049, 0.80242915, 0.75870445,\n",
       "        0.        , 0.64048583, 0.55951417, 0.80242915, 0.84129555,\n",
       "        0.        , 1.        , 0.70688259, 0.58218623, 0.58218623,\n",
       "        0.67287449, 0.75384615, 0.6534413 , 0.60647773, 0.42186235,\n",
       "        0.55951417, 0.75870445, 0.59838057, 0.04615385, 0.80242915,\n",
       "        0.69230769, 0.19433198, 0.70688259, 0.69230769, 0.75384615,\n",
       "        1.        , 0.48178138, 0.34251012, 0.48178138, 0.60647773,\n",
       "        0.63238866, 0.63238866, 0.67287449, 0.69230769, 0.1757085 ,\n",
       "        0.63238866, 0.37004049, 0.        , 0.63238866, 0.75384615,\n",
       "        0.80242915, 0.        , 0.        , 0.59838057, 0.04615385,\n",
       "        0.70688259, 0.        , 0.37004049, 0.60647773, 0.58218623,\n",
       "        0.84129555, 0.19433198, 0.37004049, 0.60647773, 0.75384615,\n",
       "        0.58218623, 0.80242915, 0.48178138, 0.63238866, 0.84129555,\n",
       "        0.55951417, 0.64048583, 0.57246964, 0.59838057, 0.60647773,\n",
       "        0.75384615, 0.58218623, 0.57246964, 0.80242915, 0.55951417,\n",
       "        0.37004049, 0.75384615, 0.60647773, 0.80242915, 0.59838057,\n",
       "        0.19433198, 1.        , 0.57246964, 0.75384615, 0.        ,\n",
       "        0.64048583, 0.67287449, 0.84129555, 0.11093117, 0.        ,\n",
       "        0.75384615, 0.75384615, 0.6534413 , 0.70688259, 0.70688259,\n",
       "        0.69230769, 0.70688259, 0.58218623, 0.75384615, 0.59838057,\n",
       "        0.68582996, 0.48178138, 0.60647773, 0.69230769, 0.37004049,\n",
       "        0.59838057, 0.        , 0.19433198, 1.        , 0.37004049,\n",
       "        0.27935223, 0.59838057, 0.27935223, 0.27935223, 0.        ,\n",
       "        0.55951417, 0.64048583, 0.1757085 , 0.59838057, 0.60647773,\n",
       "        0.        , 0.1757085 , 0.6534413 , 0.80242915, 0.27935223,\n",
       "        0.04615385, 0.60647773, 1.        , 0.04615385, 0.19433198,\n",
       "        0.80242915, 0.19433198, 0.19433198, 0.64048583, 0.19433198]),\n",
       " 'description_num_words': array([0.01348315, 0.01348315, 0.03595506, 0.00449438, 0.00674157,\n",
       "        0.00449438, 0.04494382, 0.00674157, 0.00898876, 0.02247191,\n",
       "        0.02247191, 0.        , 0.04269663, 0.01348315, 0.01123596,\n",
       "        0.06741573, 0.13483146, 0.00898876, 0.02247191, 0.0741573 ,\n",
       "        0.04044944, 0.01123596, 0.14606742, 0.06966292, 0.01123596,\n",
       "        0.01348315, 0.01797753, 0.00674157, 0.1505618 , 0.01797753,\n",
       "        0.21797753, 0.09213483, 0.08764045, 0.02921348, 0.1011236 ,\n",
       "        0.01348315, 0.0247191 , 0.0494382 , 0.17303371, 0.03146067,\n",
       "        0.02696629, 0.        , 0.08089888, 0.        , 0.02696629,\n",
       "        0.05168539, 0.03595506, 0.10337079, 0.        , 0.04044944,\n",
       "        0.05168539, 0.01797753, 0.        , 0.00674157, 0.03595506,\n",
       "        0.00898876, 0.01123596, 0.01573034, 0.00449438, 0.09213483,\n",
       "        0.13483146, 0.08089888, 0.01348315, 0.03595506, 0.01573034,\n",
       "        0.20449438, 0.        , 0.01123596, 0.05393258, 0.11011236,\n",
       "        0.02921348, 0.06741573, 0.01573034, 0.01797753, 0.11011236,\n",
       "        0.0247191 , 0.00898876, 0.02022472, 0.05842697, 0.02696629,\n",
       "        0.00898876, 0.03370787, 0.00898876, 0.1505618 , 0.0247191 ,\n",
       "        0.01797753, 0.        , 0.07640449, 0.01573034, 0.20224719,\n",
       "        0.03820225, 0.01573034, 0.12359551, 0.01573034, 0.01348315,\n",
       "        0.15505618, 0.09662921, 0.03820225, 0.        , 0.02022472,\n",
       "        0.        , 0.00898876, 0.02022472, 0.02022472, 0.00898876,\n",
       "        0.05617978, 0.02696629, 0.08089888, 0.06067416, 0.00224719,\n",
       "        0.02921348, 0.00449438, 0.01573034, 0.0494382 , 0.00224719,\n",
       "        0.0988764 , 0.02921348, 0.08764045, 0.0247191 , 0.07640449,\n",
       "        0.00449438, 0.05168539, 0.00449438, 0.01123596, 0.01348315,\n",
       "        0.04269663, 0.03146067, 0.01123596, 0.20898876, 0.01573034,\n",
       "        0.02022472, 0.0247191 , 0.00898876, 0.06067416, 0.04269663,\n",
       "        0.03146067, 0.03146067, 0.01797753, 0.00449438, 0.04494382,\n",
       "        0.02022472, 0.02921348, 0.15955056, 0.01573034, 0.00449438,\n",
       "        0.00674157, 0.01573034, 0.00898876, 0.0247191 , 0.01123596,\n",
       "        0.04044944, 0.03820225, 0.10337079, 0.14157303, 0.02022472,\n",
       "        0.01348315, 0.04044944, 0.01123596, 0.08764045, 0.01348315,\n",
       "        0.08314607, 0.15505618, 0.00224719, 0.02247191, 0.01123596,\n",
       "        0.04044944, 0.01573034, 0.07191011, 0.31910112, 0.0494382 ,\n",
       "        0.00674157, 0.03370787, 0.05617978, 0.1505618 , 0.04269663,\n",
       "        0.        , 0.04719101, 0.01123596, 0.01123596, 0.00449438,\n",
       "        0.        , 0.01797753, 0.23146067, 0.04044944, 0.10561798]),\n",
       " 'description_num_unique_words': array([0.01818182, 0.01818182, 0.04848485, 0.00606061, 0.00909091,\n",
       "        0.00606061, 0.05454545, 0.00909091, 0.01212121, 0.03030303,\n",
       "        0.03030303, 0.        , 0.03939394, 0.01818182, 0.01515152,\n",
       "        0.08484848, 0.15151515, 0.01212121, 0.03030303, 0.1       ,\n",
       "        0.05454545, 0.01515152, 0.09393939, 0.08484848, 0.01515152,\n",
       "        0.01818182, 0.02424242, 0.00909091, 0.18787879, 0.02424242,\n",
       "        0.24545455, 0.11818182, 0.10909091, 0.03939394, 0.12727273,\n",
       "        0.01818182, 0.03030303, 0.06060606, 0.21515152, 0.04242424,\n",
       "        0.03333333, 0.        , 0.10909091, 0.        , 0.03636364,\n",
       "        0.06666667, 0.04545455, 0.13030303, 0.        , 0.05454545,\n",
       "        0.06969697, 0.02424242, 0.        , 0.00909091, 0.04848485,\n",
       "        0.01212121, 0.01515152, 0.01818182, 0.00606061, 0.12121212,\n",
       "        0.16666667, 0.0969697 , 0.01818182, 0.04545455, 0.02121212,\n",
       "        0.23636364, 0.        , 0.01515152, 0.06666667, 0.13636364,\n",
       "        0.03636364, 0.08181818, 0.02121212, 0.02424242, 0.13939394,\n",
       "        0.03333333, 0.01212121, 0.02424242, 0.04545455, 0.03636364,\n",
       "        0.01212121, 0.04545455, 0.01212121, 0.16363636, 0.03333333,\n",
       "        0.02424242, 0.        , 0.1       , 0.02121212, 0.21515152,\n",
       "        0.03939394, 0.02121212, 0.15454545, 0.02121212, 0.01818182,\n",
       "        0.16666667, 0.09393939, 0.05151515, 0.        , 0.02727273,\n",
       "        0.        , 0.01212121, 0.02727273, 0.02727273, 0.01212121,\n",
       "        0.06666667, 0.03636364, 0.1030303 , 0.07878788, 0.0030303 ,\n",
       "        0.03939394, 0.00606061, 0.02121212, 0.06060606, 0.0030303 ,\n",
       "        0.11818182, 0.03939394, 0.11212121, 0.03333333, 0.0969697 ,\n",
       "        0.00606061, 0.06969697, 0.00606061, 0.01515152, 0.01818182,\n",
       "        0.05454545, 0.04242424, 0.01515152, 0.23939394, 0.02121212,\n",
       "        0.02727273, 0.03333333, 0.01212121, 0.07272727, 0.05757576,\n",
       "        0.03939394, 0.04242424, 0.02424242, 0.00606061, 0.06060606,\n",
       "        0.02727273, 0.03939394, 0.18181818, 0.02121212, 0.00606061,\n",
       "        0.00909091, 0.02121212, 0.01212121, 0.03333333, 0.01515152,\n",
       "        0.05454545, 0.03333333, 0.12121212, 0.17878788, 0.02727273,\n",
       "        0.01818182, 0.05151515, 0.01515152, 0.10606061, 0.01818182,\n",
       "        0.10606061, 0.18484848, 0.0030303 , 0.02727273, 0.01515152,\n",
       "        0.05151515, 0.02121212, 0.09393939, 0.37272727, 0.06060606,\n",
       "        0.00909091, 0.04545455, 0.06969697, 0.19090909, 0.05757576,\n",
       "        0.        , 0.05757576, 0.01515152, 0.01515152, 0.00606061,\n",
       "        0.        , 0.02424242, 0.23636364, 0.05151515, 0.13939394]),\n",
       " 'description_words_vs_unique': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.85125858, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.53165523, 1.        , 1.        ,\n",
       "        0.8993135 , 0.74370709, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.19527079, 0.85354691, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.88482075, 1.        ,\n",
       "        0.74523265, 0.9252479 , 0.88253242, 1.        , 0.89778795,\n",
       "        1.        , 0.86956522, 0.86422578, 0.87948131, 1.        ,\n",
       "        0.87948131, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.935164  , 0.90846682, 0.90007628, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.80472921, 1.        , 0.96262395,\n",
       "        0.87185355, 0.83142639, 1.        , 0.90846682, 1.        ,\n",
       "        0.77955759, 1.        , 1.        , 0.87490465, 0.87490465,\n",
       "        0.88863463, 0.84897025, 1.        , 1.        , 0.90617849,\n",
       "        1.        , 1.        , 0.84363082, 0.36384439, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.70099161, 1.        ,\n",
       "        1.        , 1.        , 0.95499619, 1.        , 0.67353166,\n",
       "        0.65293669, 1.        , 0.88863463, 1.        , 1.        ,\n",
       "        0.68726163, 0.57360793, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.81998474, 1.        , 0.91533181, 0.94431732, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.86422578, 1.        ,\n",
       "        0.82608696, 1.        , 0.9221968 , 1.        , 0.91075515,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.9221968 , 1.        , 1.        , 0.76735317, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83295195, 1.        ,\n",
       "        0.89549962, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.76125095, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.47902365, 0.80091533, 0.90236461, 1.        ,\n",
       "        1.        , 0.91762014, 1.        , 0.84363082, 1.        ,\n",
       "        0.91762014, 0.8215103 , 1.        , 0.85812357, 1.        ,\n",
       "        0.91762014, 1.        , 0.95270786, 0.79252479, 0.86422578,\n",
       "        1.        , 1.        , 0.87948131, 0.90846682, 1.        ,\n",
       "        1.        , 0.85812357, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.62471396, 0.91762014, 0.96720061]),\n",
       " 'description_punctuation': array([0.00593472, 0.00890208, 0.0148368 , 0.00296736, 0.00296736,\n",
       "        0.        , 0.02077151, 0.00296736, 0.        , 0.00593472,\n",
       "        0.0148368 , 0.        , 0.02670623, 0.00593472, 0.00593472,\n",
       "        0.02670623, 0.07715134, 0.02077151, 0.01186944, 0.04154303,\n",
       "        0.03560831, 0.00296736, 0.0504451 , 0.03560831, 0.00890208,\n",
       "        0.00593472, 0.01186944, 0.00593472, 0.02373887, 0.        ,\n",
       "        0.14540059, 0.03264095, 0.02077151, 0.02373887, 0.05637982,\n",
       "        0.        , 0.02967359, 0.02373887, 0.04451039, 0.02373887,\n",
       "        0.02670623, 0.        , 0.04451039, 0.        , 0.01780415,\n",
       "        0.02670623, 0.03560831, 0.07418398, 0.        , 0.01780415,\n",
       "        0.07715134, 0.00890208, 0.        , 0.00593472, 0.0148368 ,\n",
       "        0.00593472, 0.00593472, 0.01186944, 0.        , 0.04154303,\n",
       "        0.08308605, 0.06231454, 0.01186944, 0.0148368 , 0.00593472,\n",
       "        0.07121662, 0.        , 0.        , 0.04451039, 0.04154303,\n",
       "        0.00890208, 0.02670623, 0.01186944, 0.0148368 , 0.03264095,\n",
       "        0.02373887, 0.00296736, 0.01186944, 0.04451039, 0.02373887,\n",
       "        0.00296736, 0.02077151, 0.00296736, 0.05341246, 0.00593472,\n",
       "        0.00890208, 0.        , 0.04451039, 0.00890208, 0.46884273,\n",
       "        0.01186944, 0.00890208, 0.0504451 , 0.00296736, 0.00593472,\n",
       "        0.05934718, 0.05341246, 0.00890208, 0.        , 0.0148368 ,\n",
       "        0.        , 0.00296736, 0.00296736, 0.00593472, 0.00296736,\n",
       "        0.02077151, 0.02373887, 0.04154303, 0.03560831, 0.        ,\n",
       "        0.03560831, 0.00296736, 0.00296736, 0.02373887, 0.00296736,\n",
       "        0.04451039, 0.01780415, 0.0652819 , 0.02077151, 0.03857567,\n",
       "        0.        , 0.02670623, 0.        , 0.00890208, 0.        ,\n",
       "        0.02077151, 0.0148368 , 0.00593472, 0.17507418, 0.0148368 ,\n",
       "        0.00890208, 0.01186944, 0.00593472, 0.00593472, 0.01780415,\n",
       "        0.02373887, 0.01780415, 0.00593472, 0.00296736, 0.02373887,\n",
       "        0.02077151, 0.02077151, 0.07121662, 0.02670623, 0.        ,\n",
       "        0.00296736, 0.00890208, 0.00296736, 0.0148368 , 0.00296736,\n",
       "        0.0148368 , 0.02373887, 0.03857567, 0.07418398, 0.0148368 ,\n",
       "        0.00296736, 0.01186944, 0.        , 0.02967359, 0.00296736,\n",
       "        0.02670623, 0.0652819 , 0.        , 0.00593472, 0.00593472,\n",
       "        0.02373887, 0.00890208, 0.02670623, 0.09792285, 0.04451039,\n",
       "        0.        , 0.0148368 , 0.02373887, 0.08011869, 0.03560831,\n",
       "        0.        , 0.0148368 , 0.00593472, 0.00593472, 0.        ,\n",
       "        0.        , 0.01780415, 0.0504451 , 0.00890208, 0.10089021]),\n",
       " 'description_num': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04      , 0.        , 0.01333333, 0.        ,\n",
       "        0.01333333, 0.        , 0.        , 0.        , 0.01333333,\n",
       "        0.01333333, 0.01333333, 0.        , 0.        , 0.01333333,\n",
       "        0.01333333, 0.        , 0.18666667, 0.        , 0.        ,\n",
       "        0.01333333, 0.01333333, 0.        , 0.        , 0.02666667,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06666667,\n",
       "        0.        , 0.        , 0.01333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01333333, 0.        , 0.        ,\n",
       "        0.01333333, 0.02666667, 0.01333333, 0.        , 0.01333333,\n",
       "        0.        , 0.        , 0.        , 0.01333333, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01333333,\n",
       "        0.01333333, 0.        , 0.        , 0.01333333, 0.01333333,\n",
       "        0.02666667, 0.        , 0.01333333, 0.        , 0.        ,\n",
       "        0.        , 0.02666667, 0.        , 0.        , 0.02666667,\n",
       "        0.01333333, 0.        , 0.        , 0.10666667, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.04      , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06666667,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01333333, 0.04      , 0.01333333, 0.        , 0.        ,\n",
       "        0.        , 0.01333333, 0.        , 0.        , 0.        ,\n",
       "        0.02666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01333333, 0.01333333, 0.        ,\n",
       "        0.01333333, 0.        , 0.        , 0.        , 0.01333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.02666667,\n",
       "        0.        , 0.01333333, 0.        , 0.10666667, 0.        ,\n",
       "        0.        , 0.01333333, 0.        , 0.01333333, 0.        ,\n",
       "        0.01333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01333333, 0.        , 0.        , 0.01333333,\n",
       "        0.        , 0.08      , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02666667, 0.01333333, 0.01333333, 0.        ,\n",
       "        0.        , 0.09333333, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.02666667, 0.08      ,\n",
       "        0.        , 0.02666667, 0.        , 0.02666667, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.06666667, 0.04      , 0.01333333]),\n",
       " 'title_num_words': array([0.22222222, 0.22222222, 0.11111111, 0.        , 0.22222222,\n",
       "        0.11111111, 0.44444444, 0.11111111, 0.        , 0.33333333,\n",
       "        0.55555556, 0.        , 0.66666667, 0.22222222, 0.33333333,\n",
       "        0.22222222, 0.22222222, 0.22222222, 0.11111111, 0.55555556,\n",
       "        0.22222222, 0.11111111, 0.11111111, 0.44444444, 0.        ,\n",
       "        0.        , 0.22222222, 0.11111111, 0.11111111, 0.        ,\n",
       "        0.66666667, 0.22222222, 0.22222222, 0.33333333, 0.55555556,\n",
       "        0.11111111, 0.11111111, 0.22222222, 0.22222222, 0.33333333,\n",
       "        0.55555556, 0.22222222, 0.33333333, 0.22222222, 0.22222222,\n",
       "        0.22222222, 0.22222222, 0.55555556, 0.55555556, 0.11111111,\n",
       "        0.33333333, 0.        , 0.55555556, 0.11111111, 0.22222222,\n",
       "        0.11111111, 0.11111111, 0.22222222, 0.44444444, 0.44444444,\n",
       "        0.22222222, 0.44444444, 0.22222222, 0.11111111, 0.22222222,\n",
       "        0.55555556, 0.33333333, 0.11111111, 0.44444444, 0.55555556,\n",
       "        0.44444444, 0.22222222, 0.        , 0.        , 0.44444444,\n",
       "        0.11111111, 0.11111111, 0.        , 0.22222222, 0.33333333,\n",
       "        0.33333333, 0.22222222, 0.11111111, 0.22222222, 0.44444444,\n",
       "        0.11111111, 0.11111111, 0.22222222, 0.11111111, 0.77777778,\n",
       "        0.44444444, 0.55555556, 0.55555556, 0.33333333, 0.        ,\n",
       "        0.66666667, 0.22222222, 0.11111111, 0.11111111, 0.44444444,\n",
       "        0.        , 0.33333333, 0.        , 0.11111111, 0.44444444,\n",
       "        0.22222222, 0.11111111, 0.55555556, 0.22222222, 0.        ,\n",
       "        0.55555556, 0.        , 0.        , 0.        , 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.66666667, 0.11111111, 0.33333333,\n",
       "        0.        , 0.22222222, 0.55555556, 0.44444444, 0.        ,\n",
       "        0.55555556, 0.22222222, 0.33333333, 0.66666667, 0.11111111,\n",
       "        0.11111111, 0.22222222, 0.        , 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.66666667, 0.22222222, 0.11111111, 0.33333333,\n",
       "        0.44444444, 0.88888889, 0.33333333, 0.        , 0.        ,\n",
       "        0.        , 0.11111111, 0.        , 0.22222222, 0.11111111,\n",
       "        0.        , 0.11111111, 0.22222222, 0.11111111, 0.        ,\n",
       "        0.44444444, 0.        , 0.55555556, 0.22222222, 0.11111111,\n",
       "        0.44444444, 0.22222222, 0.11111111, 0.33333333, 0.11111111,\n",
       "        0.        , 0.11111111, 0.44444444, 0.33333333, 0.33333333,\n",
       "        0.11111111, 0.11111111, 0.33333333, 0.44444444, 0.55555556,\n",
       "        0.22222222, 0.44444444, 0.        , 0.33333333, 0.11111111,\n",
       "        0.22222222, 0.11111111, 0.33333333, 0.22222222, 0.33333333]),\n",
       " 'title_num_unique_words': array([0.22222222, 0.22222222, 0.11111111, 0.        , 0.22222222,\n",
       "        0.11111111, 0.44444444, 0.11111111, 0.        , 0.33333333,\n",
       "        0.55555556, 0.        , 0.66666667, 0.22222222, 0.33333333,\n",
       "        0.22222222, 0.22222222, 0.22222222, 0.11111111, 0.55555556,\n",
       "        0.22222222, 0.11111111, 0.11111111, 0.44444444, 0.        ,\n",
       "        0.        , 0.22222222, 0.11111111, 0.11111111, 0.        ,\n",
       "        0.66666667, 0.22222222, 0.22222222, 0.33333333, 0.55555556,\n",
       "        0.11111111, 0.11111111, 0.22222222, 0.22222222, 0.33333333,\n",
       "        0.55555556, 0.22222222, 0.33333333, 0.22222222, 0.22222222,\n",
       "        0.22222222, 0.22222222, 0.55555556, 0.55555556, 0.11111111,\n",
       "        0.33333333, 0.        , 0.55555556, 0.11111111, 0.22222222,\n",
       "        0.11111111, 0.11111111, 0.22222222, 0.44444444, 0.44444444,\n",
       "        0.22222222, 0.44444444, 0.22222222, 0.11111111, 0.22222222,\n",
       "        0.55555556, 0.33333333, 0.11111111, 0.44444444, 0.55555556,\n",
       "        0.44444444, 0.22222222, 0.        , 0.        , 0.44444444,\n",
       "        0.11111111, 0.11111111, 0.        , 0.22222222, 0.33333333,\n",
       "        0.33333333, 0.22222222, 0.11111111, 0.22222222, 0.44444444,\n",
       "        0.11111111, 0.11111111, 0.22222222, 0.11111111, 0.77777778,\n",
       "        0.44444444, 0.55555556, 0.55555556, 0.33333333, 0.        ,\n",
       "        0.66666667, 0.22222222, 0.11111111, 0.11111111, 0.44444444,\n",
       "        0.        , 0.33333333, 0.        , 0.11111111, 0.44444444,\n",
       "        0.22222222, 0.11111111, 0.55555556, 0.22222222, 0.        ,\n",
       "        0.55555556, 0.        , 0.        , 0.        , 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.66666667, 0.11111111, 0.33333333,\n",
       "        0.        , 0.22222222, 0.55555556, 0.44444444, 0.        ,\n",
       "        0.55555556, 0.22222222, 0.33333333, 0.66666667, 0.11111111,\n",
       "        0.11111111, 0.22222222, 0.        , 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.66666667, 0.22222222, 0.11111111, 0.33333333,\n",
       "        0.44444444, 0.88888889, 0.33333333, 0.        , 0.        ,\n",
       "        0.        , 0.11111111, 0.        , 0.22222222, 0.11111111,\n",
       "        0.        , 0.11111111, 0.22222222, 0.11111111, 0.        ,\n",
       "        0.44444444, 0.        , 0.55555556, 0.22222222, 0.11111111,\n",
       "        0.44444444, 0.22222222, 0.11111111, 0.33333333, 0.11111111,\n",
       "        0.        , 0.11111111, 0.44444444, 0.33333333, 0.33333333,\n",
       "        0.11111111, 0.11111111, 0.33333333, 0.44444444, 0.55555556,\n",
       "        0.22222222, 0.44444444, 0.        , 0.33333333, 0.11111111,\n",
       "        0.22222222, 0.11111111, 0.33333333, 0.22222222, 0.33333333]),\n",
       " 'title_words_vs_unique': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'title_punctuation': array([0.22222222, 0.        , 0.        , 0.        , 0.11111111,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.11111111,\n",
       "        0.55555556, 0.        , 0.        , 0.11111111, 0.        ,\n",
       "        0.        , 0.11111111, 0.        , 0.22222222, 0.55555556,\n",
       "        0.11111111, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.55555556, 0.11111111, 0.        , 0.11111111, 0.11111111,\n",
       "        0.        , 0.        , 0.11111111, 0.        , 0.22222222,\n",
       "        0.55555556, 0.11111111, 0.11111111, 0.        , 0.11111111,\n",
       "        0.        , 0.22222222, 0.66666667, 0.        , 0.        ,\n",
       "        0.22222222, 0.        , 0.22222222, 0.22222222, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11111111, 0.33333333,\n",
       "        0.11111111, 0.22222222, 0.11111111, 0.        , 0.11111111,\n",
       "        0.        , 0.11111111, 0.        , 0.        , 0.55555556,\n",
       "        0.22222222, 0.        , 0.        , 0.        , 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.22222222, 0.        , 0.        , 0.        ,\n",
       "        0.11111111, 0.        , 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.        , 0.        , 0.55555556, 0.        , 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.11111111,\n",
       "        0.        , 0.11111111, 0.11111111, 0.        , 0.        ,\n",
       "        0.55555556, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.11111111, 0.        , 0.        ,\n",
       "        0.        , 0.11111111, 0.55555556, 0.        , 0.        ,\n",
       "        0.55555556, 0.        , 0.        , 0.11111111, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.11111111, 0.22222222, 0.11111111, 0.        , 0.        ,\n",
       "        0.22222222, 0.        , 0.33333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.11111111,\n",
       "        0.        , 0.11111111, 0.11111111, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.11111111, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.11111111,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.55555556,\n",
       "        0.        , 0.11111111, 0.        , 0.11111111, 0.        ,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.        , 0.        ]),\n",
       " 'title_num': array([0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
       "        0.        , 0.33333333, 0.        , 0.        , 0.        ,\n",
       "        0.33333333, 0.        , 0.33333333, 0.        , 0.        ,\n",
       "        0.        , 0.33333333, 0.33333333, 0.        , 0.33333333,\n",
       "        0.33333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33333333, 0.33333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.33333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.33333333, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333333, 0.        , 0.33333333,\n",
       "        0.        , 0.33333333, 0.33333333, 0.        , 0.        ,\n",
       "        0.66666667, 0.33333333, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.33333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.66666667, 0.        , 0.        ,\n",
       "        0.        , 0.33333333, 0.33333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.66666667, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33333333, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.66666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333333, 0.        , 0.33333333,\n",
       "        0.        , 0.33333333, 0.66666667, 0.        , 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.66666667, 0.        ,\n",
       "        0.33333333, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'title_desc_len_ratio': array([0.06030672, 0.06030672, 0.01586531, 0.04669152, 0.10628421,\n",
       "        0.09434473, 0.03307632, 0.07053558, 0.02763024, 0.05102046,\n",
       "        0.07702898, 0.14203284, 0.04910037, 0.06030672, 0.09434473,\n",
       "        0.01288044, 0.00607284, 0.084849  , 0.02502939, 0.02427881,\n",
       "        0.02160813, 0.04669152, 0.00337162, 0.02138121, 0.02286492,\n",
       "        0.01946112, 0.04669152, 0.07053558, 0.00324507, 0.01492272,\n",
       "        0.00924972, 0.00924972, 0.00976465, 0.03988392, 0.01769813,\n",
       "        0.03988392, 0.02286492, 0.01769813, 0.00453676, 0.03716088,\n",
       "        0.06501968, 0.4280219 , 0.01449506, 0.4280219 , 0.032029  ,\n",
       "        0.01691263, 0.02427881, 0.01729665, 0.85700547, 0.01409359,\n",
       "        0.02286492, 0.01492272, 0.85700547, 0.07053558, 0.02427881,\n",
       "        0.05622216, 0.04669152, 0.05266126, 0.23740908, 0.01605732,\n",
       "        0.00607284, 0.01836143, 0.06030672, 0.01586531, 0.05266126,\n",
       "        0.00836822, 0.57101642, 0.04669152, 0.02763024, 0.01619696,\n",
       "        0.05011278, 0.01288044, 0.01691263, 0.01492272, 0.01333428,\n",
       "        0.02286492, 0.05622216, 0.01333428, 0.01492272, 0.04302589,\n",
       "        0.11340601, 0.02584979, 0.05622216, 0.00534844, 0.05863101,\n",
       "        0.03080712, 0.28502737, 0.011292  , 0.03478695, 0.0116062 ,\n",
       "        0.03876678, 0.10628421, 0.01435542, 0.07053558, 0.01946112,\n",
       "        0.01333428, 0.00878715, 0.01492272, 0.28502737, 0.07053558,\n",
       "        0.14203284, 0.11340601, 0.01333428, 0.02763024, 0.14203284,\n",
       "        0.01553366, 0.0210321 , 0.02221907, 0.01435542, 0.07053558,\n",
       "        0.06030672, 0.04669152, 0.01691263, 0.0052568 , 0.14203284,\n",
       "        0.00539208, 0.01946112, 0.02406934, 0.02286492, 0.01537656,\n",
       "        0.04669152, 0.01691263, 0.28502737, 0.1182237 , 0.01946112,\n",
       "        0.04194366, 0.02763024, 0.09434473, 0.0096861 , 0.03478695,\n",
       "        0.02763024, 0.03478695, 0.02763024, 0.00924972, 0.01333428,\n",
       "        0.0180996 , 0.0657528 , 0.04669152, 0.09434473, 0.02626872,\n",
       "        0.07053558, 0.09099329, 0.00698052, 0.01691263, 0.04669152,\n",
       "        0.03478695, 0.03478695, 0.02763024, 0.03478695, 0.04669152,\n",
       "        0.00656595, 0.01492272, 0.00816748, 0.0035069 , 0.01333428,\n",
       "        0.10118724, 0.00656595, 0.14203284, 0.00976465, 0.03988392,\n",
       "        0.01785522, 0.00516516, 0.14203284, 0.05102046, 0.04669152,\n",
       "        0.00656595, 0.03478695, 0.02070045, 0.00303778, 0.02391224,\n",
       "        0.07053558, 0.01691263, 0.0210321 , 0.00955519, 0.04194366,\n",
       "        0.4280219 , 0.03154025, 0.02286492, 0.09434473, 0.09434473,\n",
       "        0.4280219 , 0.03080712, 0.00453676, 0.02160813, 0.01095162]),\n",
       " 'seq_description': array([[   0,    0,    0, ...,  401,   55,  801],\n",
       "        [   0,    0,    0, ..., 3517,    4, 6080],\n",
       "        [   0,    0,    0, ..., 1480, 1883,   33],\n",
       "        ...,\n",
       "        [   0,    0,    0, ...,  410,   19,   65],\n",
       "        [   0,    0,    0, ...,  146,   20,   63],\n",
       "        [   0,    0,    0, ..., 3814, 3815, 6794]], dtype=int32),\n",
       " 'seq_title': array([[   0,    0,    0, ..., 3516,    5,  921],\n",
       "        [   0,    0,    0, ..., 1236,    5,  429],\n",
       "        [   0,    0,    0, ...,    0, 2462, 6081],\n",
       "        ...,\n",
       "        [   0,    0,    0, ..., 2656,  508, 1282],\n",
       "        [   0,    0,    0, ..., 2021, 2022, 6782],\n",
       "        [   0,    0,    0, ..., 2662, 2016, 2023]], dtype=int32)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
